{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9350e9f0-5844-4f50-9834-7a669c9006f2",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Problem Statement:**\n",
    "\n",
    "Goal: Create a unified hybrid framework that adapts to the commodity type and automatically selects or combines the best models accordingly.\n",
    "\n",
    "We loaded historical data from 2003-April 2025 alonmg with new realtime data to predict price with pre trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcc731a-53b5-4620-b088-efb51fbc8dd7",
   "metadata": {},
   "source": [
    "## Step 8 Processing Real Time Data with Pre Trained Models\n",
    "\n",
    "##### Sourcing Key Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2fe22d6-25d1-4d64-8b49-1379718636b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import os \n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import statsmodels.formula.api as smf\n",
    "# from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "#from pmdarima.arima import auto_arima\n",
    "import pmdarima as pm\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import math\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import os\n",
    "import itertools\n",
    "import requests\n",
    "import yfinance as yf\n",
    "from scipy.stats import randint\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "#from arch import arch_model\n",
    "from transformers import pipeline\n",
    "#from xgboost import XGBRegressor\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451b2c08-188a-4f03-9f68-74982a216b65",
   "metadata": {},
   "source": [
    "##### Define constant Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fa3528a-b459-48a0-9c2d-a515f0723723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constant values\n",
    "# Your API Key from FRED\n",
    "api_key = 'a27b910873da479a5561ea08035a6c79'\n",
    "# API Key for Alpha Vantage (Replace with your actual key)\n",
    "API_KEY_alpha = \"3J4EGZCB0D7UT9WG\"\n",
    "# genertae your APi key from here: https://www.alphavantage.co/\n",
    "\n",
    "#update the below code for any new precious Metal\n",
    "\n",
    "data_ticker_map = {\n",
    "            'GOLD' : 'GC=F',\n",
    "            'SILVER': 'SI=F',\n",
    "            'CRUDE_OIL': 'CL=F'}\n",
    "\n",
    "data_file_mapping = {\n",
    "            'GOLD' : '../../Data/Historical_Gold_data_April_2015.csv',\n",
    "           'SILVER': '../../Data/Historical_Silver_data_April_2015.csv',\n",
    "           'CRUDE_OIL': '../../Data/Historical_Crude_oil_data_April_2015.csv',}\n",
    "\n",
    "Live_Sentiments_file_name = 'Live_Sentiments.csv'\n",
    "Live_Sentiments_file_dir = '../../Sentiments'\n",
    "Historical_Sentiments_file_name = 'Historical_Sentiments.csv'\n",
    "Historical_Sentiments_file_dir = '../../Sentiments'\n",
    "\n",
    "best_models_dir = {'GOLD': '../../Models/GOLD_MODELS', 'SILVER' : '../../Models/SILVER_MODELS', 'CRUDE_OIL': '../../Models/CRUDE_OIL_MODELS'}\n",
    "hybrid_models_dir = {'GOLD': '../../Models/GOLD_HYBRID_MODELS', 'SILVER' : '../../Models/SILVER_HYBRID_MODELS', 'CRUDE_OIL': '../../Models/CRUDE_OIL_HYBRID_MODELS'}\n",
    "hybrid_meta_models_dir = {'GOLD': '../../Models/GOLD_HYBRID_MODELS/Meta', 'SILVER' : '../../Models/SILVER_HYBRID_MODELS/Meta', 'CRUDE_OIL': '../../Models/CRUDE_OIL_HYBRID_MODELS/Meta'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1db13ce-91b8-4dad-859f-4036235e59b7",
   "metadata": {},
   "source": [
    "### Enter Commodity Name for which you want to predict Price EX: GOLD, SILVER, CRUDE OIL etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "705fe956-2422-454f-87be-2ac355994ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "commodity = 'CRUDE_OIL' #input('Enter the Commodity Name')\n",
    "filename =  data_file_mapping.get(commodity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52ca900-0131-4051-95ee-8391f7f091b2",
   "metadata": {},
   "source": [
    "## Data Sourcing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972ee017-b4f3-4f1a-aba3-79a7a7754262",
   "metadata": {},
   "source": [
    "### Historical Data Sourcing\n",
    "\n",
    "##### Yahoo finance is not reliable and having issues, download data from 2003-01-01 - 2025-03-15 via yf api."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f93fae-040f-4126-a2c1-9865a4fcff41",
   "metadata": {},
   "source": [
    "##### Define function to download Historical data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5993c70-5986-4f42-bb63-7c6315de6074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to download historical price data\n",
    "def download_price_data(ticker, start='2015-01-01', end='2025-04-28'):\n",
    "    # Download the data\n",
    "    data = yf.download(ticker, start=start, end=end)\n",
    "    \n",
    "    # Reset index to turn 'Date' into a regular column\n",
    "    data.reset_index(inplace=True)\n",
    "    \n",
    "    # Flatten the columns if there are multiple levels\n",
    "    data.columns = data.columns.get_level_values(0) if isinstance(data.columns, pd.MultiIndex) else data.columns\n",
    "    \n",
    "    # Select necessary columns only\n",
    "    data = data[['Date', 'Open', 'High', 'Low', 'Close', 'Volume']]\n",
    "    return data\n",
    "\n",
    "# Load or download data for each commodity\n",
    "def load_or_download_data(ticker, filename):\n",
    "    if os.path.exists(filename):\n",
    "        # Read the CSV, treating the first row as the header\n",
    "        data = pd.read_csv(filename, header=0)\n",
    "        \n",
    "        # Convert 'Date' column to datetime format, and handle parsing errors\n",
    "        data['Date'] = pd.to_datetime(data['Date'], errors='coerce')\n",
    "        \n",
    "        # Remove any rows where 'Date' could not be parsed and resulted in NaT\n",
    "        data = data.dropna(subset=['Date'])\n",
    "    else:\n",
    "        # Download the data\n",
    "        data = download_price_data(ticker)\n",
    "        \n",
    "        # Save to CSV with a single header row\n",
    "        data.to_csv(filename, index=False)\n",
    "    \n",
    "    # Ensure the 'Close' column is numeric\n",
    "    data['Close'] = pd.to_numeric(data['Close'], errors='coerce')\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b2a3e34-735b-4477-9271-bc0add04b847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from Historical file id Data available in file : ../../Data/Historical_Crude_oil_data_April_2015.csv\n",
      "Ticker code for CRUDE_OIL : CL=F\n",
      "YF.download() has changed argument auto_adjust default to True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "############# Reading Data Sources #################\n",
    "print(f'Loading from Historical file id Data available in file : {filename}')\n",
    "ticker = data_ticker_map.get(commodity)\n",
    "print(f'Ticker code for {commodity} : {ticker}')\n",
    "commodity_data = load_or_download_data(ticker, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab7f3311-e940-4c9d-a3d3-ec7c9f71a68e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Price</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>53.759998</td>\n",
       "      <td>55.110001</td>\n",
       "      <td>52.029999</td>\n",
       "      <td>52.689999</td>\n",
       "      <td>268708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>52.610001</td>\n",
       "      <td>52.730000</td>\n",
       "      <td>49.680000</td>\n",
       "      <td>50.040001</td>\n",
       "      <td>375782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.369999</td>\n",
       "      <td>47.549999</td>\n",
       "      <td>47.930000</td>\n",
       "      <td>451642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-07</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>49.310001</td>\n",
       "      <td>46.830002</td>\n",
       "      <td>48.650002</td>\n",
       "      <td>460083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>48.779999</td>\n",
       "      <td>49.650002</td>\n",
       "      <td>47.730000</td>\n",
       "      <td>48.790001</td>\n",
       "      <td>362081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2588</th>\n",
       "      <td>2025-04-21</td>\n",
       "      <td>64.300003</td>\n",
       "      <td>64.419998</td>\n",
       "      <td>62.450001</td>\n",
       "      <td>63.080002</td>\n",
       "      <td>82671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2589</th>\n",
       "      <td>2025-04-22</td>\n",
       "      <td>63.430000</td>\n",
       "      <td>65.089996</td>\n",
       "      <td>63.430000</td>\n",
       "      <td>64.309998</td>\n",
       "      <td>297928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2590</th>\n",
       "      <td>2025-04-23</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>64.870003</td>\n",
       "      <td>61.529999</td>\n",
       "      <td>62.270000</td>\n",
       "      <td>397841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2591</th>\n",
       "      <td>2025-04-24</td>\n",
       "      <td>62.340000</td>\n",
       "      <td>63.310001</td>\n",
       "      <td>61.990002</td>\n",
       "      <td>62.790001</td>\n",
       "      <td>264908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2592</th>\n",
       "      <td>2025-04-25</td>\n",
       "      <td>62.860001</td>\n",
       "      <td>63.410000</td>\n",
       "      <td>61.799999</td>\n",
       "      <td>63.020000</td>\n",
       "      <td>283758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2593 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Price       Date       Open       High        Low      Close  Volume\n",
       "0     2015-01-02  53.759998  55.110001  52.029999  52.689999  268708\n",
       "1     2015-01-05  52.610001  52.730000  49.680000  50.040001  375782\n",
       "2     2015-01-06  50.000000  50.369999  47.549999  47.930000  451642\n",
       "3     2015-01-07  48.000000  49.310001  46.830002  48.650002  460083\n",
       "4     2015-01-08  48.779999  49.650002  47.730000  48.790001  362081\n",
       "...          ...        ...        ...        ...        ...     ...\n",
       "2588  2025-04-21  64.300003  64.419998  62.450001  63.080002   82671\n",
       "2589  2025-04-22  63.430000  65.089996  63.430000  64.309998  297928\n",
       "2590  2025-04-23  64.000000  64.870003  61.529999  62.270000  397841\n",
       "2591  2025-04-24  62.340000  63.310001  61.990002  62.790001  264908\n",
       "2592  2025-04-25  62.860001  63.410000  61.799999  63.020000  283758\n",
       "\n",
       "[2593 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commodity_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d0b1de-a054-4fe8-b221-eb83e5b00995",
   "metadata": {},
   "source": [
    "### Sourcing Market data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92b23c1-8321-4785-b8e3-4e9fb8a86b81",
   "metadata": {},
   "source": [
    "####  GDP data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039f663d-4beb-4fa9-8d87-781b4f50d8a8",
   "metadata": {},
   "source": [
    "##### Define function which will convert Yearly GDP data to daily GDP data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f27a97c8-2cb5-44a5-b4f5-de2132bb9ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_gdp_to_daily(gdp_df):\n",
    "    daily_gdp = []\n",
    "    for index, row in gdp_df.iterrows():\n",
    "        month_start = row['Date']\n",
    "        value = row['Value']\n",
    "        month_days = pd.date_range(start=month_start, end=month_start + pd.offsets.MonthEnd(0), freq='D')\n",
    "        for day in month_days:\n",
    "            daily_gdp.append({'Date': day, 'Value': value})\n",
    "    return pd.DataFrame(daily_gdp)\n",
    "\n",
    "\n",
    "def preprocess_gdp_data(gdp_data):\n",
    "    gdp_data['Date'] = pd.to_datetime(gdp_data['Date'])\n",
    "    return expand_gdp_to_daily(gdp_data)\n",
    "\n",
    "\n",
    "def fetch_world_bank_data(indicator, country='USA', start_year='2003', end_year='2025'):\n",
    "    url = f'http://api.worldbank.org/v2/country/{country}/indicator/{indicator}?date={start_year}:{end_year}&format=json'\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        data = response.json()\n",
    "        if len(data) < 2 or 'message' in data[1]:\n",
    "            print(\"No data found for the specified parameters.\")\n",
    "            return None\n",
    "        df = pd.json_normalize(data[1])\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        df = df[(df['date'] >= f'{start_year}-01-01') & (df['date'] <= f'{end_year}-12-31')]\n",
    "        df = df[['date', 'value']]\n",
    "        df.columns = ['Date', 'Value']\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e30dbe92-f02b-499f-8c08-d2802a038022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>GDP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-01-03</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-01-04</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-01-05</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>2003-01-27</td>\n",
       "      <td>11456450000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>2003-01-28</td>\n",
       "      <td>11456450000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>2003-01-29</td>\n",
       "      <td>11456450000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>2003-01-30</td>\n",
       "      <td>11456450000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>2003-01-31</td>\n",
       "      <td>11456450000000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>682 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date               GDP\n",
       "0   2024-01-01               NaT\n",
       "1   2024-01-02               NaT\n",
       "2   2024-01-03               NaT\n",
       "3   2024-01-04               NaT\n",
       "4   2024-01-05               NaT\n",
       "..         ...               ...\n",
       "677 2003-01-27  11456450000000.0\n",
       "678 2003-01-28  11456450000000.0\n",
       "679 2003-01-29  11456450000000.0\n",
       "680 2003-01-30  11456450000000.0\n",
       "681 2003-01-31  11456450000000.0\n",
       "\n",
       "[682 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############### sourcing world GDP data #################################################\n",
    "gdp_data = fetch_world_bank_data('NY.GDP.MKTP.CD', country='USA', start_year='2003', end_year='2025')\n",
    "daily_gdp_data = preprocess_gdp_data(gdp_data)\n",
    "daily_gdp_data.rename(columns={'Value':'GDP'},inplace=True)\n",
    "daily_gdp_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c76cd28-d934-415c-b38f-e9f82c663ecc",
   "metadata": {},
   "source": [
    "####  Interest rate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93c134a1-53b0-4f5e-aea3-cc1ee200a54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_28728\\1493415932.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  daily_interest_rate_data.rename(columns={'date':'Date'},inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Interest_rates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1954-07-01</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1954-07-02</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1954-07-03</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1954-07-04</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954-07-05</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25838</th>\n",
       "      <td>2025-03-28</td>\n",
       "      <td>4.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25839</th>\n",
       "      <td>2025-03-29</td>\n",
       "      <td>4.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25840</th>\n",
       "      <td>2025-03-30</td>\n",
       "      <td>4.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25841</th>\n",
       "      <td>2025-03-31</td>\n",
       "      <td>4.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25842</th>\n",
       "      <td>2025-04-01</td>\n",
       "      <td>4.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25843 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date  Interest_rates\n",
       "0     1954-07-01            0.80\n",
       "1     1954-07-02            0.80\n",
       "2     1954-07-03            0.80\n",
       "3     1954-07-04            0.80\n",
       "4     1954-07-05            0.80\n",
       "...          ...             ...\n",
       "25838 2025-03-28            4.33\n",
       "25839 2025-03-29            4.33\n",
       "25840 2025-03-30            4.33\n",
       "25841 2025-03-31            4.33\n",
       "25842 2025-04-01            4.33\n",
       "\n",
       "[25843 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "############## Sourcing Interest rate data ################################\n",
    "from fredapi import Fred\n",
    "\n",
    "# Your API Key from FRED\n",
    "api_key = 'a27b910873da479a5561ea08035a6c79'\n",
    "\n",
    "# Initialize the FRED API\n",
    "fred = Fred(api_key=api_key)\n",
    "\n",
    "# Fetch the Federal Funds Rate data (you can change this to any other indicator)\n",
    "# Federal Funds Rate is often identified by the FRED ID 'FEDFUNDS'\n",
    "interest_rate_data = fred.get_series('FEDFUNDS' ,start_date='2003-01-01')\n",
    "\n",
    "# Convert the data into a DataFrame for better handling\n",
    "interest_rate_df = pd.DataFrame(interest_rate_data)\n",
    "interest_rate_df.columns = ['Interest_rates']\n",
    "\n",
    "# Reset the index to have 'Date' as a column\n",
    "interest_rate_df.reset_index(inplace=True)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming `interest_rate_df` already exists with 'Date' and 'Interest_rates' columns\n",
    "\n",
    "# Convert 'Date' column to datetime format if it’s not already\n",
    "interest_rate_df['Date'] = pd.to_datetime(interest_rate_df['index'])\n",
    "interest_rate_df.drop(columns=['index'], inplace=True)  # Drop the old index column if needed\n",
    "\n",
    "# Create a date range for every day from the start to the end of the interest rate data\n",
    "start_date = interest_rate_df['Date'].min()\n",
    "end_date = interest_rate_df['Date'].max()\n",
    "date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "\n",
    "# Create a new DataFrame with daily dates as a column\n",
    "daily_interest_rate_df = pd.DataFrame({'date': date_range})\n",
    "\n",
    "# Add a 'month' and 'year' column to `interest_rate_df` for easy merging\n",
    "interest_rate_df['year'] = interest_rate_df['Date'].dt.year\n",
    "interest_rate_df['month'] = interest_rate_df['Date'].dt.month\n",
    "\n",
    "# Merge monthly data with daily data on matching 'year' and 'month'\n",
    "daily_interest_rate_df['year'] = daily_interest_rate_df['date'].dt.year\n",
    "daily_interest_rate_df['month'] = daily_interest_rate_df['date'].dt.month\n",
    "\n",
    "# Perform a left join on 'year' and 'month' columns\n",
    "daily_interest_rate_df = daily_interest_rate_df.merge(\n",
    "    interest_rate_df[['year', 'month', 'Interest_rates']],\n",
    "    on=['year', 'month'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Drop the extra columns, keep only 'date' and 'Interest_rates'\n",
    "daily_interest_rate_data = daily_interest_rate_df[['date', 'Interest_rates']]\n",
    "daily_interest_rate_data.rename(columns={'date':'Date'},inplace=True)\n",
    "daily_interest_rate_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6ee9a5-1801-49d5-81ea-c456500d1d16",
   "metadata": {},
   "source": [
    "####  GDP to Debt data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "567f72fe-d4e9-4468-b58e-bbd7b0f7cb18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>DebtToGDP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>33.267642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-02</td>\n",
       "      <td>33.267642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>33.267642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>33.267642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>33.267642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8397</th>\n",
       "      <td>2022-12-28</td>\n",
       "      <td>110.385332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8398</th>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>110.385332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8399</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>110.385332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8400</th>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>110.385332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8401</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8402 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date   DebtToGDP\n",
       "0    2000-01-01   33.267642\n",
       "1    2000-01-02   33.267642\n",
       "2    2000-01-03   33.267642\n",
       "3    2000-01-04   33.267642\n",
       "4    2000-01-05   33.267642\n",
       "...         ...         ...\n",
       "8397 2022-12-28  110.385332\n",
       "8398 2022-12-29  110.385332\n",
       "8399 2022-12-30  110.385332\n",
       "8400 2022-12-31  110.385332\n",
       "8401 2023-01-01    0.000000\n",
       "\n",
       "[8402 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################## GDP to Debt DATA ###############################\n",
    "import wbdata\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "# Set the start and end dates for the data\n",
    "start_date = datetime.datetime(2000, 1, 1)\n",
    "end_date = datetime.datetime(2023, 1, 1)\n",
    "\n",
    "# List of indicators to retrieve (Government Debt to GDP ratio)\n",
    "indicators = {'GC.DOD.TOTL.GD.ZS': 'Government Debt to GDP'}\n",
    "\n",
    "# Fetch data from the World Bank API for the USA\n",
    "government_debt_data = wbdata.get_dataframe(indicators, country='USA')\n",
    "\n",
    "# Fill missing values in `Government Debt to GDP` with 0\n",
    "government_debt_data['Government Debt to GDP'] = government_debt_data['Government Debt to GDP'].fillna(0)\n",
    "\n",
    "# Reset index to make `date` a regular column and convert it to datetime\n",
    "government_debt_data.reset_index(inplace=True)\n",
    "government_debt_data['date'] = pd.to_datetime(government_debt_data['date'])\n",
    "\n",
    "# Add a 'year' column to `government_debt_data` to help with mapping\n",
    "government_debt_data['year'] = government_debt_data['date'].dt.year\n",
    "\n",
    "# Create a dictionary for quick lookup of Debt to GDP per year\n",
    "debt_to_gdp_dict = government_debt_data.set_index('year')['Government Debt to GDP'].to_dict()\n",
    "\n",
    "# Create a date range for every day from the start to the end date\n",
    "date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "\n",
    "# Create a new DataFrame with daily dates as a column\n",
    "daily_debt_data = pd.DataFrame({'date': date_range})\n",
    "\n",
    "# Map each date in `daily_debt_data` to the corresponding Debt to GDP value for that year\n",
    "daily_debt_data['DebtToGDP'] = daily_debt_data['date'].dt.year.map(debt_to_gdp_dict)\n",
    "daily_debt_data.rename(columns={'date':'Date'},inplace=True)\n",
    "\n",
    "daily_debt_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e825e2-39b4-4c68-a964-455dba12a9cd",
   "metadata": {},
   "source": [
    "####  Inflation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1ecd240-27db-4ed3-8a77-28265c97b00f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Inflation_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1954-07-01</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1954-08-01</td>\n",
       "      <td>1.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1954-09-01</td>\n",
       "      <td>1.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1954-10-01</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954-11-01</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>2024-12-01</td>\n",
       "      <td>4.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>4.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>2025-02-01</td>\n",
       "      <td>4.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>4.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>2025-04-01</td>\n",
       "      <td>4.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>850 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  Inflation_rate\n",
       "0   1954-07-01            0.80\n",
       "1   1954-08-01            1.22\n",
       "2   1954-09-01            1.07\n",
       "3   1954-10-01            0.85\n",
       "4   1954-11-01            0.83\n",
       "..         ...             ...\n",
       "845 2024-12-01            4.48\n",
       "846 2025-01-01            4.33\n",
       "847 2025-02-01            4.33\n",
       "848 2025-03-01            4.33\n",
       "849 2025-04-01            4.33\n",
       "\n",
       "[850 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############## inflation data #################\n",
    "# Get historical CPI data (Consumer Price Index) to calculate inflation\n",
    "cpi_data = fred.get_series('CPIAUCSL', start_date='2003-01-01')\n",
    "\n",
    "\n",
    "\n",
    "# Convert the data into a DataFrame for better handling\n",
    "Inflation_data = pd.DataFrame(interest_rate_data)\n",
    "Inflation_data.columns = ['Inflation_rate']\n",
    "\n",
    "# Reset the index to have 'Date' as a column\n",
    "Inflation_data.reset_index(inplace=True)\n",
    "Inflation_data.rename(columns={'index':'Date'},inplace=True)\n",
    "# Print the first few rows\n",
    "Inflation_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562fba95-b00b-45b6-aad1-0f3b6e657f3b",
   "metadata": {},
   "source": [
    "####  ETF data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "119bd0ae-8466-40c9-87d4-4d7426fafca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full JSON response: {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'observation_start': '2003-01-01', 'observation_end': '2024-11-01', 'units': 'lin', 'output_type': 1, 'file_type': 'json', 'order_by': 'observation_date', 'sort_order': 'asc', 'count': 224, 'offset': 0, 'limit': 100000, 'observations': [{'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2003-01-01', 'value': '2.25'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2003-02-01', 'value': '2.25'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2003-03-01', 'value': '2.25'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2003-04-01', 'value': '2.25'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2003-05-01', 'value': '2.25'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2003-06-01', 'value': '2'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2003-07-01', 'value': '2'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2003-08-01', 'value': '2'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2003-09-01', 'value': '2'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2003-10-01', 'value': '2'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2003-11-01', 'value': '2'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2003-12-01', 'value': '2'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2004-01-01', 'value': '2'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2004-02-01', 'value': '2'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2004-03-01', 'value': '2'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2004-04-01', 'value': '2'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2004-05-01', 'value': '2'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2004-06-01', 'value': '2.25'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2004-07-01', 'value': '2.25'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2004-08-01', 'value': '2.5'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2004-09-01', 'value': '2.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2004-10-01', 'value': '2.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2004-11-01', 'value': '3'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2004-12-01', 'value': '3.25'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2005-01-01', 'value': '3.25'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2005-02-01', 'value': '3.5'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2005-03-01', 'value': '3.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2005-04-01', 'value': '3.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2005-05-01', 'value': '4'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2005-06-01', 'value': '4.25'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2005-07-01', 'value': '4.25'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2005-08-01', 'value': '4.5'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2005-09-01', 'value': '4.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2005-10-01', 'value': '4.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2005-11-01', 'value': '5'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2005-12-01', 'value': '5.25'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2006-01-01', 'value': '5.5'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2006-02-01', 'value': '5.5'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2006-03-01', 'value': '5.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2006-04-01', 'value': '5.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2006-05-01', 'value': '6'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2006-06-01', 'value': '6.25'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2006-07-01', 'value': '6.25'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2006-08-01', 'value': '6.25'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2006-09-01', 'value': '6.25'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2006-10-01', 'value': '6.25'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2006-11-01', 'value': '6.25'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2006-12-01', 'value': '6.25'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2007-01-01', 'value': '6.25'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2007-02-01', 'value': '6.25'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2007-03-01', 'value': '6.25'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2007-04-01', 'value': '6.25'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2007-05-01', 'value': '6.25'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2007-06-01', 'value': '6.25'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2007-07-01', 'value': '6.25'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2007-08-01', 'value': '5.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2007-09-01', 'value': '5.25'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2007-10-01', 'value': '5'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2007-11-01', 'value': '5'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2007-12-01', 'value': '4.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2008-01-01', 'value': '3.5'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2008-02-01', 'value': '3.5'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2008-03-01', 'value': '2.5'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2008-04-01', 'value': '2.25'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2008-05-01', 'value': '2.25'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2008-06-01', 'value': '2.25'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2008-07-01', 'value': '2.25'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2008-08-01', 'value': '2.25'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2008-09-01', 'value': '2.25'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2008-10-01', 'value': '1.25'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2008-11-01', 'value': '1.25'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2008-12-01', 'value': '0.5'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2009-01-01', 'value': '0.5'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2009-02-01', 'value': '0.5'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2009-03-01', 'value': '0.5'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2009-04-01', 'value': '0.5'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2009-05-01', 'value': '0.5'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2009-06-01', 'value': '0.5'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2009-07-01', 'value': '0.5'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2009-08-01', 'value': '0.5'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2009-09-01', 'value': '0.5'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2009-10-01', 'value': '0.5'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2009-11-01', 'value': '0.5'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2009-12-01', 'value': '0.5'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2010-01-01', 'value': '0.5'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2010-02-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2010-03-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2010-04-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2010-05-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2010-06-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2010-07-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2010-08-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2010-09-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2010-10-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2010-11-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2010-12-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2011-01-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2011-02-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2011-03-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2011-04-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2011-05-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2011-06-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2011-07-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2011-08-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2011-09-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2011-10-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2011-11-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2011-12-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2012-01-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2012-02-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2012-03-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2012-04-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2012-05-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2012-06-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2012-07-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2012-08-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2012-09-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2012-10-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2012-11-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2012-12-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2013-01-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2013-02-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2013-03-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2013-04-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2013-05-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2013-06-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2013-07-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2013-08-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2013-09-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2013-10-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2013-11-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2013-12-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2014-01-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2014-02-01', 'value': '0.75000'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2014-03-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2014-04-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2014-05-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2014-06-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2014-07-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2014-08-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2014-09-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2014-10-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2014-11-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2014-12-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2015-01-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2015-02-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2015-03-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2015-04-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2015-05-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2015-06-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2015-07-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2015-08-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2015-09-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2015-10-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2015-11-01', 'value': '0.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2015-12-01', 'value': '1'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2016-01-01', 'value': '1'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2016-02-01', 'value': '1'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2016-03-01', 'value': '1'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2016-04-01', 'value': '1'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2016-05-01', 'value': '1'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2016-06-01', 'value': '1'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2016-07-01', 'value': '1'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2016-08-01', 'value': '1'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2016-09-01', 'value': '1'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2016-10-01', 'value': '1'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2016-11-01', 'value': '1'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2016-12-01', 'value': '1.25'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2017-01-01', 'value': '1.25'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2017-02-01', 'value': '1.25'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2017-03-01', 'value': '1.5'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2017-04-01', 'value': '1.5'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2017-05-01', 'value': '1.5'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2017-06-01', 'value': '1.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2017-07-01', 'value': '1.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2017-08-01', 'value': '1.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2017-09-01', 'value': '1.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2017-10-01', 'value': '1.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2017-11-01', 'value': '1.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2017-12-01', 'value': '2.0'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2018-01-01', 'value': '2.0'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2018-02-01', 'value': '2.0'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2018-03-01', 'value': '2.25'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2018-04-01', 'value': '2.25'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2018-05-01', 'value': '2.25'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2018-06-01', 'value': '2.5'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2018-07-01', 'value': '2.5'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2018-08-01', 'value': '2.5'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2018-09-01', 'value': '2.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2018-10-01', 'value': '2.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2018-11-01', 'value': '2.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2018-12-01', 'value': '3.0'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2019-01-01', 'value': '3.0'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2019-02-01', 'value': '3.0'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2019-03-01', 'value': '3.0'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2019-04-01', 'value': '3.0'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2019-05-01', 'value': '3.0'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2019-06-01', 'value': '3.0'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2019-07-01', 'value': '3.0'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2019-08-01', 'value': '2.75'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2019-09-01', 'value': '2.5'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2019-10-01', 'value': '2.25'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2019-11-01', 'value': '2.25'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2019-12-01', 'value': '2.25'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2020-01-01', 'value': '2.25'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2020-02-01', 'value': '2.25'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2020-03-01', 'value': '0.25'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2020-04-01', 'value': '0.25'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2020-05-01', 'value': '0.25'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2020-06-01', 'value': '0.25'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2020-07-01', 'value': '0.25'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2020-08-01', 'value': '0.25'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2020-09-01', 'value': '0.25'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2020-10-01', 'value': '0.25'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2020-11-01', 'value': '0.25'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2020-12-01', 'value': '0.25'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2021-01-01', 'value': '0.25'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2021-02-01', 'value': '0.25'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2021-03-01', 'value': '0.25'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2021-04-01', 'value': '0.25'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2021-05-01', 'value': '0.25'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2021-06-01', 'value': '0.25'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2021-07-01', 'value': '0.25'}, {'realtime_start': '2025-04-12', 'realtime_end': '2025-04-12', 'date': '2021-08-01', 'value': '0.25'}]}\n",
      "           realtime_start realtime_end        date  ETF_Value\n",
      "Date                                                         \n",
      "2003-01-01     2025-04-12   2025-04-12  2003-01-01       2.25\n",
      "2003-02-01     2025-04-12   2025-04-12  2003-02-01       2.25\n",
      "2003-03-01     2025-04-12   2025-04-12  2003-03-01       2.25\n",
      "2003-04-01     2025-04-12   2025-04-12  2003-04-01       2.25\n",
      "2003-05-01     2025-04-12   2025-04-12  2003-05-01       2.25\n"
     ]
    }
   ],
   "source": [
    "################ Gold ETF data ###########################################\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Fetch ETF data from FRED API\n",
    "def fetch_fred_etf_data(series_id, api_key, start_date='2003-01-01', end_date='2024-11-01'):\n",
    "    url = f'https://api.stlouisfed.org/fred/series/observations?series_id={series_id}&api_key={api_key}&file_type=json&observation_start={start_date}&observation_end={end_date}'\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    \n",
    "    # Print the entire JSON response for inspection\n",
    "    print(\"Full JSON response:\", data)\n",
    "    \n",
    "    # Check for errors in the JSON response\n",
    "    if \"observations\" not in data:\n",
    "        print(\"Error: 'observations' key not found in the response. Check the series ID or API request.\")\n",
    "        return None\n",
    "    \n",
    "    # Parse JSON data into a DataFrame\n",
    "    etf_df = pd.DataFrame(data['observations'])\n",
    "    etf_df['Date'] = pd.to_datetime(etf_df['date'])\n",
    "    etf_df['Date'] = etf_df['Date'].dt.tz_localize(None).dt.date \n",
    "    etf_df['value'] = pd.to_numeric(etf_df['value'], errors='coerce')\n",
    "    etf_df.set_index('Date', inplace=True)\n",
    "    \n",
    "    return etf_df\n",
    "\n",
    "# Example usage\n",
    "api_key = 'a27b910873da479a5561ea08035a6c79'\n",
    "series_id = 'INTDSRUSM193N'  # Replace with a valid series ID from FRED\n",
    "etf_data = fetch_fred_etf_data(series_id, api_key)\n",
    "\n",
    "\n",
    "etf_data.rename(columns={'value':'ETF_Value'},inplace=True)\n",
    "# Only print if data retrieval was successful\n",
    "if etf_data is not None:\n",
    "    print(etf_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b06659b-180b-48dd-9d21-4ed1c8d47cf5",
   "metadata": {},
   "source": [
    "## Sourcing Sentiment Data and Apply BERT\n",
    "\n",
    "#### Sourcing Live Sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa600903-d3cb-4193-8b66-d00908731511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Lenovo\\myvenv\\myenv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Lenovo\\myvenv\\myenv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Set up NewsAPI\n",
    "API_KEY = \"250e051931514de6b0e5120412c4e3ad\"\n",
    "NEWS_API_URL = \"https://newsapi.org/v2/everything\"\n",
    "\n",
    "# Fetch news using query\n",
    "def fetch_news(query, language=\"en\", page_size=100):\n",
    "    params = {\n",
    "        \"q\": query,\n",
    "        \"language\": language,\n",
    "        \"apiKey\": API_KEY,\n",
    "        \"pageSize\": page_size,\n",
    "        \"sortBy\": \"publishedAt\",\n",
    "    }\n",
    "    response = requests.get(NEWS_API_URL, params=params)\n",
    "    data = response.json()\n",
    "    \n",
    "    if data.get(\"status\") == \"ok\":\n",
    "        articles = data.get(\"articles\", [])\n",
    "        return [(article[\"publishedAt\"], article[\"title\"]) for article in articles]\n",
    "    else:\n",
    "        print(\"Error fetching news:\", data)\n",
    "        return []\n",
    "\n",
    "# Load FinBERT pipeline\n",
    "sentiment_pipeline = pipeline(\"text-classification\", model=\"ProsusAI/finbert\")\n",
    "\n",
    "def analyze_sentiment(texts):\n",
    "    sentiments = sentiment_pipeline(texts, truncation=True)\n",
    "    return [sent[\"label\"] for sent in sentiments]\n",
    "\n",
    "# Combined sentiment fetcher for crude oil-related queries\n",
    "def get_oil_sentiment():\n",
    "    queries = [\n",
    "    \"crude oil\",\n",
    "    \"Brent crude\",\n",
    "    \"WTI\",\n",
    "    \"oil price\",\n",
    "    \"oil futures\",\n",
    "    \"oil market\",\n",
    "    \"oil production\",\n",
    "    \"OPEC\",\n",
    "    \"oil demand\"\n",
    "]\n",
    "    all_articles = []\n",
    "\n",
    "    for query in queries:\n",
    "        articles = fetch_news(query)\n",
    "        all_articles.extend(articles)\n",
    "\n",
    "    if not all_articles:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df = pd.DataFrame(all_articles, columns=[\"Date\", \"Headline\"])\n",
    "    df[\"Sentiment\"] = analyze_sentiment(df[\"Headline\"].tolist())\n",
    "    df.to_csv(\"gold_sentiment_data.csv\", index=False)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5dd1ac-2526-4cbd-ab6b-42ed89b5956d",
   "metadata": {},
   "source": [
    "#### Apply Sentiment analysis on Live data and save them in disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80223850-39d2-4791-a7ba-6aa85f5aef63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Date                                           Headline  \\\n",
      "0  2025-04-30T10:00:45Z            Turkey’s Pivotal Moment With Azerbaijan   \n",
      "1  2025-04-30T10:00:00Z  Trump’s Policies Are Creating Uncertainty for ...   \n",
      "2  2025-04-30T09:53:27Z  Stocks to Buy | Resilience & Rebalancing: Indi...   \n",
      "3  2025-04-30T09:51:38Z         TotalEnergies Profits Drop As Prices Slide   \n",
      "4  2025-04-30T09:38:18Z  HPCL, ADNOC Trading ink their first LNG tradin...   \n",
      "\n",
      "  Sentiment  \n",
      "0   neutral  \n",
      "1  negative  \n",
      "2   neutral  \n",
      "3  negative  \n",
      "4   neutral  \n",
      "                   Date                                           Headline  \\\n",
      "0  2025-04-30T10:00:45Z            Turkey’s Pivotal Moment With Azerbaijan   \n",
      "1  2025-04-30T10:00:00Z  Trump’s Policies Are Creating Uncertainty for ...   \n",
      "2  2025-04-30T09:53:27Z  Stocks to Buy | Resilience & Rebalancing: Indi...   \n",
      "3  2025-04-30T09:51:38Z         TotalEnergies Profits Drop As Prices Slide   \n",
      "4  2025-04-30T09:38:18Z  HPCL, ADNOC Trading ink their first LNG tradin...   \n",
      "\n",
      "  Sentiment  Sentiment_score  \n",
      "0   neutral                0  \n",
      "1  negative               -1  \n",
      "2   neutral                0  \n",
      "3  negative               -1  \n",
      "4   neutral                0  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-04-30</td>\n",
       "      <td>Turkey’s Pivotal Moment With Azerbaijan</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-04-30</td>\n",
       "      <td>Trump’s Policies Are Creating Uncertainty for ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-04-30</td>\n",
       "      <td>Stocks to Buy | Resilience &amp; Rebalancing: Indi...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-04-30</td>\n",
       "      <td>TotalEnergies Profits Drop As Prices Slide</td>\n",
       "      <td>negative</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-04-30</td>\n",
       "      <td>HPCL, ADNOC Trading ink their first LNG tradin...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date                                           Headline Sentiment  \\\n",
       "0  2025-04-30            Turkey’s Pivotal Moment With Azerbaijan   neutral   \n",
       "1  2025-04-30  Trump’s Policies Are Creating Uncertainty for ...  negative   \n",
       "2  2025-04-30  Stocks to Buy | Resilience & Rebalancing: Indi...   neutral   \n",
       "3  2025-04-30         TotalEnergies Profits Drop As Prices Slide  negative   \n",
       "4  2025-04-30  HPCL, ADNOC Trading ink their first LNG tradin...   neutral   \n",
       "\n",
       "   Sentiment_score  \n",
       "0                0  \n",
       "1               -1  \n",
       "2                0  \n",
       "3               -1  \n",
       "4                0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the new data\n",
    "import os\n",
    "Live_Sentiments_file = os.path.join(Live_Sentiments_file_dir, commodity.upper(), Live_Sentiments_file_name)\n",
    "if os.path.exists(Live_Sentiments_file):\n",
    "    # sentiment_df = get_oil_sentiment()\n",
    "    # sentiment_df.to_csv(Live_Sentiments_file, index=False)\n",
    "    sentiment_df =  pd.read_csv(Live_Sentiments_file)  # File does not exist\n",
    "else:\n",
    "    # Fetch sentiment data\n",
    "    sentiment_df = get_oil_sentiment()\n",
    "    sentiment_df.to_csv(Live_Sentiments_file, index=False)\n",
    "print(sentiment_df.head())\n",
    "sentiment_df['Sentiment_score'] = sentiment_df['Sentiment'].apply(lambda x: 1 if x == 'positive' else -1 if x == 'negative' else 0)\n",
    "print(sentiment_df.head())\n",
    "\n",
    "# Add sentiment data back to the news_df\n",
    "sentiment_df[['Date', 'Headline', 'Sentiment', 'Sentiment_score']]\n",
    "live_sentiments_df = sentiment_df[['Date', 'Headline', 'Sentiment', 'Sentiment_score']]\n",
    "# # Print out the resulting dataframe\n",
    "# print(news_df[['Date', 'Title', 'Sentiment']].head())\n",
    "\n",
    "# Convert Date column to datetime and add a range of days around each event\n",
    "live_sentiments_df['Date'] = pd.to_datetime(live_sentiments_df['Date'])\n",
    "\n",
    "\n",
    "\n",
    "live_sentiments_df['Date'] = pd.to_datetime(live_sentiments_df['Date'], errors='coerce')\n",
    "live_sentiments_df['Date'] = live_sentiments_df['Date'].dt.tz_localize(None).dt.date \n",
    "live_sentiments_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f489c044-d2c6-4e0c-a2ed-f668db19468c",
   "metadata": {},
   "source": [
    "#### Load Historical Sentiment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa81d788-907a-4f90-b833-8221f9166d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "# Historical_Sentiments_file = os.path.join(Historical_Sentiments_file_dir, commodity.upper(), Historical_Sentiments_file_name)\n",
    "# #Detect Invalid Dates\n",
    "# def is_invalid_date(date_str):\n",
    "#     try:\n",
    "#         pd.to_datetime(date_str, format=\"%d-%m-%Y\", errors=\"raise\")\n",
    "#         return False  # Valid date\n",
    "#     except:\n",
    "#         return True   # Invalid date\n",
    "\n",
    "\n",
    "\n",
    "# if os.path.exists(Historical_Sentiments_file) and commodity.upper()==\"GOLD\":\n",
    "#         historical_news_df =  pd.read_csv(Historical_Sentiments_file)  # File does not exist\n",
    "#         print(historical_news_df)\n",
    "# elif commodity.upper()==\"GOLD\" :\n",
    "#     # Fetch sentiment data\n",
    "#     historical_sentiment_data = pd.read_csv(\"C:/Users/Lenovo/OneDrive/Desktop/War/code/data/gold_historical_sentiments.csv\", usecols=[\"Dates\",\"Price Sentiment\", \"News\"])\n",
    "#     historical_sentiment_data = historical_sentiment_data[~historical_sentiment_data[\"Dates\"].astype(str).apply(is_invalid_date)]\n",
    "    \n",
    "    \n",
    "#     # Add sentiment data back to the news_df\n",
    "#     # # Print out the resulting dataframe\n",
    "#     # print(news_df[['Date', 'Title', 'Sentiment']].head())\n",
    "#     historical_news_df = historical_sentiment_data[['Dates', 'News', 'Price Sentiment', 'Sentiment_score']]\n",
    "#     historical_news_df.rename(columns = {'News':'Headline', 'Dates':'Date', 'Price Sentiment':'Sentiment'}, inplace = True)\n",
    "    \n",
    "#     # Convert Date column to datetime and add a range of days around each event\n",
    "#     historical_news_df['Date'] = pd.to_datetime(historical_news_df['Date'])\n",
    "#     historical_news_df['Date'] = pd.to_datetime(historical_news_df['Date'], errors='coerce')\n",
    "#     historical_news_df['Date'] = historical_news_df['Date'].dt.tz_localize(None).dt.date \n",
    "\n",
    "#     historical_news_df = historical_news_df[['Date','Headline']]\n",
    "#     historical_news_df[\"Sentiment_score\"] = analyze_sentiment(historical_news_df[\"Headline\"].tolist(), batch_size=16)\n",
    "#     historical_news_df['Sentiment_score'] = historical_news_df['Sentiment_score'].apply(lambda x: 1 if x == 'positive' else -1 if x == 'negative' else 0)\n",
    "#     historical_news_df.to_csv(Historical_Sentiments_file, index=False)\n",
    "# else:\n",
    "#     historical_news_df=live_sentiments_df\n",
    "import pandas as pd\n",
    "import requests\n",
    "from transformers import pipeline\n",
    "\n",
    "# Step 1: Define the events\n",
    "events = {\n",
    "    '2003-03-20': 'Iraq War begins, leading to regional instability and oil price increase',\n",
    "    '2011-01-25': 'Arab Spring uprisings cause oil production disruptions',\n",
    "    '2022-02-24': 'Russian invasion of Ukraine impacts oil prices due to sanctions and supply disruptions',\n",
    "    '2008-09-15': 'Aftermath of 2008 Financial Crisis on Oil Prices',\n",
    "    '2024-01-10': 'U.S. Announces New Sanctions on Russia',\n",
    "    '2024-02-15': 'Ukraine Military Counteroffensive',\n",
    "    '2024-03-05': 'Israel-Hamas Conflict Escalation',\n",
    "    '2024-04-12': 'Iran Nuclear Talks Stalled'\n",
    "}\n",
    "\n",
    "# Step 2: Create a DataFrame for the events\n",
    "event_df = pd.DataFrame(list(events.items()), columns=['Date', 'Title'])\n",
    "\n",
    "# Step 3: Load the sentiment analysis pipeline\n",
    "sentiment_pipeline = pipeline('sentiment-analysis')\n",
    "\n",
    "# Step 4: Perform sentiment analysis on the event titles\n",
    "event_sentiments = sentiment_pipeline(event_df['Title'].tolist())\n",
    "\n",
    "# Step 5: Convert sentiment analysis results to DataFrame\n",
    "sentiment_df = pd.DataFrame(event_sentiments)\n",
    "\n",
    "# Step 6: Map sentiment labels to numerical values\n",
    "event_df['Sentiment'] = sentiment_df['label'].apply(lambda x: 1 if x == 'POSITIVE' else -1 if x == 'NEGATIVE' else 0)\n",
    "# Step 8: Convert 'Date' to datetime for merging\n",
    "\n",
    "event_df['Date'] = pd.to_datetime(event_df['Date'], errors='coerce')\n",
    "event_df['Date'] = event_df['Date'].dt.tz_localize(None).dt.date \n",
    "#gold_data['Date'] = pd.to_datetime(gold_data['Date']).dt.tz_localize(None).dt.date \n",
    "event_df.head()\n",
    "historical_news_df = event_df\n",
    "historical_news_df.rename(columns={'Sentiment':'Sentiment_score'},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c0a39c-0c32-4385-ab2c-6c8bd74e0227",
   "metadata": {},
   "source": [
    "## Step 2 : Data Preprocessing and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aca0077-123a-4e07-9d82-577fedc4bf70",
   "metadata": {},
   "source": [
    "### 2.1 Null Value Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2a5d3b5-4224-4239-ab04-5779102201d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in [commodity_data]:\n",
    "    data.dropna(subset=['Date', 'Close'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c5ecd8-7e4f-4c06-9124-586fc2718f83",
   "metadata": {},
   "source": [
    "### 2.2 Converting Values to Datetime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c74c1b1c-0f70-43fe-901d-f8d19cd8d926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COnvert into date format\n",
    "# Historical Data\n",
    "# Convert Date column in gold_data to remove timezone\n",
    "commodity_data['Date'] = commodity_data['Date'].dt.tz_localize(None).dt.date \n",
    "\n",
    "# Market Economic Data\n",
    "daily_gdp_data['Date'] = daily_gdp_data['Date'].dt.tz_localize(None).dt.date \n",
    "interest_rate_df['Date'] = interest_rate_df['Date'].dt.tz_localize(None).dt.date \n",
    "Inflation_data['Date'] = Inflation_data['Date'].dt.tz_localize(None).dt.date \n",
    "daily_debt_data['Date'] = daily_debt_data['Date'].dt.tz_localize(None).dt.date "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e36fa9a-9d8e-4372-91c3-2b056b2315cb",
   "metadata": {},
   "source": [
    "### 2.3 Merging all source data to final data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "adecd7a3-6043-4a1a-b658-8ff89e3b7b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all dataframes on 'Date' with 'gold_data' as the base (left join)\n",
    "merged_data = commodity_data.merge(daily_gdp_data, on='Date', how='left') \\\n",
    "                       .merge(interest_rate_df, on='Date', how='left') \\\n",
    "                       .merge(Inflation_data, on='Date', how='left') \\\n",
    "                       .merge(daily_debt_data, on='Date', how='left') \\\n",
    "                        .merge(etf_data[['ETF_Value']], on='Date', how='left')\n",
    "\n",
    "merged_data.drop(columns=['year','month'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa172db1-2cce-4b66-a3a5-0edcc22f819c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2593 entries, 0 to 2592\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Date            2593 non-null   object \n",
      " 1   Open            2593 non-null   float64\n",
      " 2   High            2593 non-null   float64\n",
      " 3   Low             2593 non-null   float64\n",
      " 4   Close           2593 non-null   float64\n",
      " 5   Volume          2593 non-null   int64  \n",
      " 6   GDP             181 non-null    object \n",
      " 7   Interest_rates  81 non-null     float64\n",
      " 8   Inflation_rate  81 non-null     float64\n",
      " 9   DebtToGDP       2012 non-null   float64\n",
      " 10  ETF_Value       51 non-null     float64\n",
      "dtypes: float64(8), int64(1), object(2)\n",
      "memory usage: 223.0+ KB\n",
      "Date                 0\n",
      "Open                 0\n",
      "High                 0\n",
      "Low                  0\n",
      "Close                0\n",
      "Volume               0\n",
      "GDP               2412\n",
      "Interest_rates    2512\n",
      "Inflation_rate    2512\n",
      "DebtToGDP          581\n",
      "ETF_Value         2542\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "merged_data.info()\n",
    "# Print summary of missing values after imputation\n",
    "print(merged_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493ab45e-9781-455b-ae33-e80eb5458484",
   "metadata": {},
   "source": [
    "### 2.4 Processing NULL values from merged data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ae9305d-926c-4e1e-94f6-1fe3b11ac56e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date              0\n",
      "Open              0\n",
      "High              0\n",
      "Low               0\n",
      "Close             0\n",
      "Volume            0\n",
      "GDP               0\n",
      "Interest_rates    0\n",
      "Inflation_rate    0\n",
      "DebtToGDP         0\n",
      "ETF_Value         0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_28728\\3625551758.py:6: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_data[numeric_cols] = merged_data[numeric_cols].fillna(method=\"ffill\")  # Forward Fill (Recommended)\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_28728\\3625551758.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_data[\"Volume\"].fillna(merged_data[\"Volume\"].median(), inplace=True)\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_28728\\3625551758.py:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_data[col].fillna(merged_data[col].mean(), inplace=True)  # Mean Imputation\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_28728\\3625551758.py:14: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_data[col].fillna(merged_data[col].mean(), inplace=True)  # Mean Imputation\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_28728\\3625551758.py:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_data[col].fillna(0, inplace=True)  # Mean Imputation\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convert numeric columns from object type to float (if needed)\n",
    "numeric_cols = [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]\n",
    "merged_data[numeric_cols] = merged_data[numeric_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "# Handle Financial Market Data (Time-series features)\n",
    "merged_data[numeric_cols] = merged_data[numeric_cols].fillna(method=\"ffill\")  # Forward Fill (Recommended)\n",
    "\n",
    "#  Handle Volume (Typically Skewed, Use Median)\n",
    "merged_data[\"Volume\"].fillna(merged_data[\"Volume\"].median(), inplace=True)\n",
    "\n",
    "# 🔹 Handle Economic Indicators (Use Mean or Interpolation)\n",
    "econ_cols = [\"GDP\", \"DebtToGDP\", \"Interest_rates\", \"Inflation_rate\", \"ETF_Value\"]\n",
    "for col in econ_cols:\n",
    "    merged_data[col].fillna(merged_data[col].mean(), inplace=True)  # Mean Imputation\n",
    "    merged_data[col].fillna(0, inplace=True)  # Mean Imputation\n",
    "\n",
    "\n",
    "# Print summary of missing values after imputation\n",
    "print(merged_data.isnull().sum())\n",
    "\n",
    "commodity_data=merged_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7246f5e-e3b6-4d9c-ba47-954e40c18fb2",
   "metadata": {},
   "source": [
    "### Outlier Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e470274-2eb0-4db6-abea-c8ff4d3588f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>GDP</th>\n",
       "      <th>Interest_rates</th>\n",
       "      <th>Inflation_rate</th>\n",
       "      <th>DebtToGDP</th>\n",
       "      <th>ETF_Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1330</th>\n",
       "      <td>2020-04-20</td>\n",
       "      <td>17.730000</td>\n",
       "      <td>17.850000</td>\n",
       "      <td>-40.320000</td>\n",
       "      <td>-37.630001</td>\n",
       "      <td>247947</td>\n",
       "      <td>2.195852e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>124.733177</td>\n",
       "      <td>1.377451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1331</th>\n",
       "      <td>2020-04-21</td>\n",
       "      <td>-14.000000</td>\n",
       "      <td>13.860000</td>\n",
       "      <td>-16.740000</td>\n",
       "      <td>10.010000</td>\n",
       "      <td>2288230</td>\n",
       "      <td>2.195852e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>124.733177</td>\n",
       "      <td>1.377451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1803</th>\n",
       "      <td>2022-03-04</td>\n",
       "      <td>107.959999</td>\n",
       "      <td>116.019997</td>\n",
       "      <td>107.250000</td>\n",
       "      <td>115.680000</td>\n",
       "      <td>493875</td>\n",
       "      <td>2.195852e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>110.385332</td>\n",
       "      <td>1.377451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1804</th>\n",
       "      <td>2022-03-07</td>\n",
       "      <td>121.330002</td>\n",
       "      <td>130.500000</td>\n",
       "      <td>115.540001</td>\n",
       "      <td>119.400002</td>\n",
       "      <td>576022</td>\n",
       "      <td>2.195852e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>110.385332</td>\n",
       "      <td>1.377451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1805</th>\n",
       "      <td>2022-03-08</td>\n",
       "      <td>120.669998</td>\n",
       "      <td>129.440002</td>\n",
       "      <td>117.070000</td>\n",
       "      <td>123.699997</td>\n",
       "      <td>583106</td>\n",
       "      <td>2.195852e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>110.385332</td>\n",
       "      <td>1.377451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1814</th>\n",
       "      <td>2022-03-21</td>\n",
       "      <td>105.129997</td>\n",
       "      <td>112.690002</td>\n",
       "      <td>104.080002</td>\n",
       "      <td>112.120003</td>\n",
       "      <td>77217</td>\n",
       "      <td>2.195852e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>110.385332</td>\n",
       "      <td>1.377451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1815</th>\n",
       "      <td>2022-03-22</td>\n",
       "      <td>112.900002</td>\n",
       "      <td>115.010002</td>\n",
       "      <td>109.300003</td>\n",
       "      <td>111.760002</td>\n",
       "      <td>318629</td>\n",
       "      <td>2.195852e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>110.385332</td>\n",
       "      <td>1.377451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1816</th>\n",
       "      <td>2022-03-23</td>\n",
       "      <td>108.849998</td>\n",
       "      <td>115.400002</td>\n",
       "      <td>108.379997</td>\n",
       "      <td>114.930000</td>\n",
       "      <td>289182</td>\n",
       "      <td>2.195852e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>110.385332</td>\n",
       "      <td>1.377451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1817</th>\n",
       "      <td>2022-03-24</td>\n",
       "      <td>114.470001</td>\n",
       "      <td>116.639999</td>\n",
       "      <td>110.610001</td>\n",
       "      <td>112.339996</td>\n",
       "      <td>307238</td>\n",
       "      <td>2.195852e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>110.385332</td>\n",
       "      <td>1.377451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818</th>\n",
       "      <td>2022-03-25</td>\n",
       "      <td>111.750000</td>\n",
       "      <td>114.120003</td>\n",
       "      <td>108.680000</td>\n",
       "      <td>113.900002</td>\n",
       "      <td>320304</td>\n",
       "      <td>2.195852e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>110.385332</td>\n",
       "      <td>1.377451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1853</th>\n",
       "      <td>2022-05-16</td>\n",
       "      <td>110.980003</td>\n",
       "      <td>114.900002</td>\n",
       "      <td>108.110001</td>\n",
       "      <td>114.199997</td>\n",
       "      <td>289127</td>\n",
       "      <td>2.195852e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>110.385332</td>\n",
       "      <td>1.377451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1854</th>\n",
       "      <td>2022-05-17</td>\n",
       "      <td>113.870003</td>\n",
       "      <td>115.559998</td>\n",
       "      <td>111.750000</td>\n",
       "      <td>112.400002</td>\n",
       "      <td>252630</td>\n",
       "      <td>2.195852e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>110.385332</td>\n",
       "      <td>1.377451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1856</th>\n",
       "      <td>2022-05-19</td>\n",
       "      <td>109.089996</td>\n",
       "      <td>112.620003</td>\n",
       "      <td>105.129997</td>\n",
       "      <td>112.209999</td>\n",
       "      <td>68511</td>\n",
       "      <td>2.195852e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>110.385332</td>\n",
       "      <td>1.377451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1857</th>\n",
       "      <td>2022-05-20</td>\n",
       "      <td>111.449997</td>\n",
       "      <td>114.040001</td>\n",
       "      <td>110.849998</td>\n",
       "      <td>113.230003</td>\n",
       "      <td>229930</td>\n",
       "      <td>2.195852e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>110.385332</td>\n",
       "      <td>1.377451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1861</th>\n",
       "      <td>2022-05-26</td>\n",
       "      <td>110.690002</td>\n",
       "      <td>114.830002</td>\n",
       "      <td>110.269997</td>\n",
       "      <td>114.089996</td>\n",
       "      <td>234752</td>\n",
       "      <td>2.195852e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>110.385332</td>\n",
       "      <td>1.377451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1862</th>\n",
       "      <td>2022-05-27</td>\n",
       "      <td>114.199997</td>\n",
       "      <td>115.300003</td>\n",
       "      <td>112.849998</td>\n",
       "      <td>115.070000</td>\n",
       "      <td>217281</td>\n",
       "      <td>2.195852e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>110.385332</td>\n",
       "      <td>1.377451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1863</th>\n",
       "      <td>2022-05-31</td>\n",
       "      <td>114.959999</td>\n",
       "      <td>119.980003</td>\n",
       "      <td>114.150002</td>\n",
       "      <td>114.669998</td>\n",
       "      <td>440796</td>\n",
       "      <td>2.195852e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>110.385332</td>\n",
       "      <td>1.377451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1864</th>\n",
       "      <td>2022-06-01</td>\n",
       "      <td>115.400002</td>\n",
       "      <td>117.870003</td>\n",
       "      <td>114.580002</td>\n",
       "      <td>115.260002</td>\n",
       "      <td>290530</td>\n",
       "      <td>2.195852e+13</td>\n",
       "      <td>1.210000</td>\n",
       "      <td>1.210000</td>\n",
       "      <td>110.385332</td>\n",
       "      <td>1.377451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1865</th>\n",
       "      <td>2022-06-02</td>\n",
       "      <td>114.800003</td>\n",
       "      <td>117.769997</td>\n",
       "      <td>111.199997</td>\n",
       "      <td>116.870003</td>\n",
       "      <td>327600</td>\n",
       "      <td>2.195852e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>110.385332</td>\n",
       "      <td>1.377451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1866</th>\n",
       "      <td>2022-06-03</td>\n",
       "      <td>117.550003</td>\n",
       "      <td>120.459999</td>\n",
       "      <td>115.230003</td>\n",
       "      <td>118.870003</td>\n",
       "      <td>240831</td>\n",
       "      <td>2.195852e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>110.385332</td>\n",
       "      <td>1.377451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867</th>\n",
       "      <td>2022-06-06</td>\n",
       "      <td>120.820000</td>\n",
       "      <td>120.989998</td>\n",
       "      <td>117.629997</td>\n",
       "      <td>118.500000</td>\n",
       "      <td>246825</td>\n",
       "      <td>2.195852e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>110.385332</td>\n",
       "      <td>1.377451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1868</th>\n",
       "      <td>2022-06-07</td>\n",
       "      <td>119.099998</td>\n",
       "      <td>120.360001</td>\n",
       "      <td>117.139999</td>\n",
       "      <td>119.410004</td>\n",
       "      <td>341694</td>\n",
       "      <td>2.195852e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>110.385332</td>\n",
       "      <td>1.377451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1869</th>\n",
       "      <td>2022-06-08</td>\n",
       "      <td>119.790001</td>\n",
       "      <td>123.180000</td>\n",
       "      <td>119.300003</td>\n",
       "      <td>122.110001</td>\n",
       "      <td>340591</td>\n",
       "      <td>2.195852e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>110.385332</td>\n",
       "      <td>1.377451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1870</th>\n",
       "      <td>2022-06-09</td>\n",
       "      <td>122.430000</td>\n",
       "      <td>122.720001</td>\n",
       "      <td>120.790001</td>\n",
       "      <td>121.510002</td>\n",
       "      <td>293295</td>\n",
       "      <td>2.195852e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>110.385332</td>\n",
       "      <td>1.377451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1871</th>\n",
       "      <td>2022-06-10</td>\n",
       "      <td>121.459999</td>\n",
       "      <td>122.750000</td>\n",
       "      <td>118.330002</td>\n",
       "      <td>120.669998</td>\n",
       "      <td>352906</td>\n",
       "      <td>2.195852e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>110.385332</td>\n",
       "      <td>1.377451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1872</th>\n",
       "      <td>2022-06-13</td>\n",
       "      <td>120.190002</td>\n",
       "      <td>122.250000</td>\n",
       "      <td>117.470001</td>\n",
       "      <td>120.930000</td>\n",
       "      <td>372403</td>\n",
       "      <td>2.195852e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>110.385332</td>\n",
       "      <td>1.377451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1873</th>\n",
       "      <td>2022-06-14</td>\n",
       "      <td>121.089996</td>\n",
       "      <td>123.680000</td>\n",
       "      <td>116.620003</td>\n",
       "      <td>118.930000</td>\n",
       "      <td>366320</td>\n",
       "      <td>2.195852e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>110.385332</td>\n",
       "      <td>1.377451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874</th>\n",
       "      <td>2022-06-15</td>\n",
       "      <td>119.070000</td>\n",
       "      <td>119.610001</td>\n",
       "      <td>114.599998</td>\n",
       "      <td>115.309998</td>\n",
       "      <td>301750</td>\n",
       "      <td>2.195852e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>110.385332</td>\n",
       "      <td>1.377451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1875</th>\n",
       "      <td>2022-06-16</td>\n",
       "      <td>115.980003</td>\n",
       "      <td>118.080002</td>\n",
       "      <td>112.309998</td>\n",
       "      <td>117.589996</td>\n",
       "      <td>162543</td>\n",
       "      <td>2.195852e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>110.385332</td>\n",
       "      <td>1.377451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1882</th>\n",
       "      <td>2022-06-28</td>\n",
       "      <td>110.180000</td>\n",
       "      <td>112.220001</td>\n",
       "      <td>109.620003</td>\n",
       "      <td>111.760002</td>\n",
       "      <td>306748</td>\n",
       "      <td>2.195852e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>110.385332</td>\n",
       "      <td>1.377451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date        Open        High         Low       Close   Volume  \\\n",
       "1330  2020-04-20   17.730000   17.850000  -40.320000  -37.630001   247947   \n",
       "1331  2020-04-21  -14.000000   13.860000  -16.740000   10.010000  2288230   \n",
       "1803  2022-03-04  107.959999  116.019997  107.250000  115.680000   493875   \n",
       "1804  2022-03-07  121.330002  130.500000  115.540001  119.400002   576022   \n",
       "1805  2022-03-08  120.669998  129.440002  117.070000  123.699997   583106   \n",
       "1814  2022-03-21  105.129997  112.690002  104.080002  112.120003    77217   \n",
       "1815  2022-03-22  112.900002  115.010002  109.300003  111.760002   318629   \n",
       "1816  2022-03-23  108.849998  115.400002  108.379997  114.930000   289182   \n",
       "1817  2022-03-24  114.470001  116.639999  110.610001  112.339996   307238   \n",
       "1818  2022-03-25  111.750000  114.120003  108.680000  113.900002   320304   \n",
       "1853  2022-05-16  110.980003  114.900002  108.110001  114.199997   289127   \n",
       "1854  2022-05-17  113.870003  115.559998  111.750000  112.400002   252630   \n",
       "1856  2022-05-19  109.089996  112.620003  105.129997  112.209999    68511   \n",
       "1857  2022-05-20  111.449997  114.040001  110.849998  113.230003   229930   \n",
       "1861  2022-05-26  110.690002  114.830002  110.269997  114.089996   234752   \n",
       "1862  2022-05-27  114.199997  115.300003  112.849998  115.070000   217281   \n",
       "1863  2022-05-31  114.959999  119.980003  114.150002  114.669998   440796   \n",
       "1864  2022-06-01  115.400002  117.870003  114.580002  115.260002   290530   \n",
       "1865  2022-06-02  114.800003  117.769997  111.199997  116.870003   327600   \n",
       "1866  2022-06-03  117.550003  120.459999  115.230003  118.870003   240831   \n",
       "1867  2022-06-06  120.820000  120.989998  117.629997  118.500000   246825   \n",
       "1868  2022-06-07  119.099998  120.360001  117.139999  119.410004   341694   \n",
       "1869  2022-06-08  119.790001  123.180000  119.300003  122.110001   340591   \n",
       "1870  2022-06-09  122.430000  122.720001  120.790001  121.510002   293295   \n",
       "1871  2022-06-10  121.459999  122.750000  118.330002  120.669998   352906   \n",
       "1872  2022-06-13  120.190002  122.250000  117.470001  120.930000   372403   \n",
       "1873  2022-06-14  121.089996  123.680000  116.620003  118.930000   366320   \n",
       "1874  2022-06-15  119.070000  119.610001  114.599998  115.309998   301750   \n",
       "1875  2022-06-16  115.980003  118.080002  112.309998  117.589996   162543   \n",
       "1882  2022-06-28  110.180000  112.220001  109.620003  111.760002   306748   \n",
       "\n",
       "               GDP  Interest_rates  Inflation_rate   DebtToGDP  ETF_Value  \n",
       "1330  2.195852e+13        1.815679        1.815679  124.733177   1.377451  \n",
       "1331  2.195852e+13        1.815679        1.815679  124.733177   1.377451  \n",
       "1803  2.195852e+13        1.815679        1.815679  110.385332   1.377451  \n",
       "1804  2.195852e+13        1.815679        1.815679  110.385332   1.377451  \n",
       "1805  2.195852e+13        1.815679        1.815679  110.385332   1.377451  \n",
       "1814  2.195852e+13        1.815679        1.815679  110.385332   1.377451  \n",
       "1815  2.195852e+13        1.815679        1.815679  110.385332   1.377451  \n",
       "1816  2.195852e+13        1.815679        1.815679  110.385332   1.377451  \n",
       "1817  2.195852e+13        1.815679        1.815679  110.385332   1.377451  \n",
       "1818  2.195852e+13        1.815679        1.815679  110.385332   1.377451  \n",
       "1853  2.195852e+13        1.815679        1.815679  110.385332   1.377451  \n",
       "1854  2.195852e+13        1.815679        1.815679  110.385332   1.377451  \n",
       "1856  2.195852e+13        1.815679        1.815679  110.385332   1.377451  \n",
       "1857  2.195852e+13        1.815679        1.815679  110.385332   1.377451  \n",
       "1861  2.195852e+13        1.815679        1.815679  110.385332   1.377451  \n",
       "1862  2.195852e+13        1.815679        1.815679  110.385332   1.377451  \n",
       "1863  2.195852e+13        1.815679        1.815679  110.385332   1.377451  \n",
       "1864  2.195852e+13        1.210000        1.210000  110.385332   1.377451  \n",
       "1865  2.195852e+13        1.815679        1.815679  110.385332   1.377451  \n",
       "1866  2.195852e+13        1.815679        1.815679  110.385332   1.377451  \n",
       "1867  2.195852e+13        1.815679        1.815679  110.385332   1.377451  \n",
       "1868  2.195852e+13        1.815679        1.815679  110.385332   1.377451  \n",
       "1869  2.195852e+13        1.815679        1.815679  110.385332   1.377451  \n",
       "1870  2.195852e+13        1.815679        1.815679  110.385332   1.377451  \n",
       "1871  2.195852e+13        1.815679        1.815679  110.385332   1.377451  \n",
       "1872  2.195852e+13        1.815679        1.815679  110.385332   1.377451  \n",
       "1873  2.195852e+13        1.815679        1.815679  110.385332   1.377451  \n",
       "1874  2.195852e+13        1.815679        1.815679  110.385332   1.377451  \n",
       "1875  2.195852e+13        1.815679        1.815679  110.385332   1.377451  \n",
       "1882  2.195852e+13        1.815679        1.815679  110.385332   1.377451  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Function to identify and remove outliers using IQR\n",
    "def identify_outliers(df):\n",
    "    # Ensure 'Close' is numeric\n",
    "    df['Close'] = pd.to_numeric(df['Close'], errors='coerce')  # Convert to float, set errors to NaN\n",
    "    df = df.dropna(subset=['Close'])  # Drop rows where 'Close' is NaN after conversion\n",
    "\n",
    "    Q1 = df['Close'].quantile(0.25)\n",
    "    Q3 = df['Close'].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    ndf = df[(df['Close'] <= lower_bound) | (df['Close'] >= upper_bound)]\n",
    "    return ndf\n",
    "\n",
    "# Apply outlier detection to the Gold dataset\n",
    "commodity_data['Close'] = pd.to_numeric(commodity_data['Close'], errors='coerce')  # Ensure 'Close' is numeric\n",
    "outlier = identify_outliers(commodity_data)\n",
    "outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c9283c04-0b76-42ce-a630-07a4786a1808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>GDP</th>\n",
       "      <th>Interest_rates</th>\n",
       "      <th>Inflation_rate</th>\n",
       "      <th>DebtToGDP</th>\n",
       "      <th>ETF_Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>53.759998</td>\n",
       "      <td>55.110001</td>\n",
       "      <td>52.029999</td>\n",
       "      <td>52.689999</td>\n",
       "      <td>268708</td>\n",
       "      <td>1.829502e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>95.956145</td>\n",
       "      <td>1.377451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>52.610001</td>\n",
       "      <td>52.730000</td>\n",
       "      <td>49.680000</td>\n",
       "      <td>50.040001</td>\n",
       "      <td>375782</td>\n",
       "      <td>1.829502e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>95.956145</td>\n",
       "      <td>1.377451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.369999</td>\n",
       "      <td>47.549999</td>\n",
       "      <td>47.930000</td>\n",
       "      <td>451642</td>\n",
       "      <td>1.829502e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>95.956145</td>\n",
       "      <td>1.377451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-07</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>49.310001</td>\n",
       "      <td>46.830002</td>\n",
       "      <td>48.650002</td>\n",
       "      <td>460083</td>\n",
       "      <td>1.829502e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>95.956145</td>\n",
       "      <td>1.377451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>48.779999</td>\n",
       "      <td>49.650002</td>\n",
       "      <td>47.730000</td>\n",
       "      <td>48.790001</td>\n",
       "      <td>362081</td>\n",
       "      <td>1.829502e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>95.956145</td>\n",
       "      <td>1.377451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2588</th>\n",
       "      <td>2025-04-21</td>\n",
       "      <td>64.300003</td>\n",
       "      <td>64.419998</td>\n",
       "      <td>62.450001</td>\n",
       "      <td>63.080002</td>\n",
       "      <td>82671</td>\n",
       "      <td>2.195852e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>105.457564</td>\n",
       "      <td>1.377451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2589</th>\n",
       "      <td>2025-04-22</td>\n",
       "      <td>63.430000</td>\n",
       "      <td>65.089996</td>\n",
       "      <td>63.430000</td>\n",
       "      <td>64.309998</td>\n",
       "      <td>297928</td>\n",
       "      <td>2.195852e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>105.457564</td>\n",
       "      <td>1.377451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2590</th>\n",
       "      <td>2025-04-23</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>64.870003</td>\n",
       "      <td>61.529999</td>\n",
       "      <td>62.270000</td>\n",
       "      <td>397841</td>\n",
       "      <td>2.195852e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>105.457564</td>\n",
       "      <td>1.377451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2591</th>\n",
       "      <td>2025-04-24</td>\n",
       "      <td>62.340000</td>\n",
       "      <td>63.310001</td>\n",
       "      <td>61.990002</td>\n",
       "      <td>62.790001</td>\n",
       "      <td>264908</td>\n",
       "      <td>2.195852e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>105.457564</td>\n",
       "      <td>1.377451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2592</th>\n",
       "      <td>2025-04-25</td>\n",
       "      <td>62.860001</td>\n",
       "      <td>63.410000</td>\n",
       "      <td>61.799999</td>\n",
       "      <td>63.020000</td>\n",
       "      <td>283758</td>\n",
       "      <td>2.195852e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>105.457564</td>\n",
       "      <td>1.377451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2593 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date       Open       High        Low      Close  Volume  \\\n",
       "0     2015-01-02  53.759998  55.110001  52.029999  52.689999  268708   \n",
       "1     2015-01-05  52.610001  52.730000  49.680000  50.040001  375782   \n",
       "2     2015-01-06  50.000000  50.369999  47.549999  47.930000  451642   \n",
       "3     2015-01-07  48.000000  49.310001  46.830002  48.650002  460083   \n",
       "4     2015-01-08  48.779999  49.650002  47.730000  48.790001  362081   \n",
       "...          ...        ...        ...        ...        ...     ...   \n",
       "2588  2025-04-21  64.300003  64.419998  62.450001  63.080002   82671   \n",
       "2589  2025-04-22  63.430000  65.089996  63.430000  64.309998  297928   \n",
       "2590  2025-04-23  64.000000  64.870003  61.529999  62.270000  397841   \n",
       "2591  2025-04-24  62.340000  63.310001  61.990002  62.790001  264908   \n",
       "2592  2025-04-25  62.860001  63.410000  61.799999  63.020000  283758   \n",
       "\n",
       "               GDP  Interest_rates  Inflation_rate   DebtToGDP  ETF_Value  \n",
       "0     1.829502e+13        1.815679        1.815679   95.956145   1.377451  \n",
       "1     1.829502e+13        1.815679        1.815679   95.956145   1.377451  \n",
       "2     1.829502e+13        1.815679        1.815679   95.956145   1.377451  \n",
       "3     1.829502e+13        1.815679        1.815679   95.956145   1.377451  \n",
       "4     1.829502e+13        1.815679        1.815679   95.956145   1.377451  \n",
       "...            ...             ...             ...         ...        ...  \n",
       "2588  2.195852e+13        1.815679        1.815679  105.457564   1.377451  \n",
       "2589  2.195852e+13        1.815679        1.815679  105.457564   1.377451  \n",
       "2590  2.195852e+13        1.815679        1.815679  105.457564   1.377451  \n",
       "2591  2.195852e+13        1.815679        1.815679  105.457564   1.377451  \n",
       "2592  2.195852e+13        1.815679        1.815679  105.457564   1.377451  \n",
       "\n",
       "[2593 rows x 11 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commodity_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b434c6a0-dbde-46fd-9979-001a6d98a0f8",
   "metadata": {},
   "source": [
    "###  Data Merging - Sentiments with Commodity Data\n",
    "\n",
    "#### Merging Live and Histrical Sentiment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27e96e5b-d535-4edc-bdf2-3c8c07250192",
   "metadata": {},
   "outputs": [],
   "source": [
    "live_sentiments_df = live_sentiments_df[['Date','Sentiment_score']]\n",
    "historical_news_df = historical_news_df[['Date','Sentiment_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "614c0dc6-097d-4c2a-846e-680f1ab6a920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Date  Sentiment_score\n",
      "883 2003-03-20               -1\n",
      "886 2008-09-15               -1\n",
      "884 2011-01-25               -1\n",
      "885 2022-02-24               -1\n",
      "887 2024-01-10               -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_28728\\3662196593.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  historical_news_df['Date'] = pd.to_datetime(historical_news_df['Date'])\n"
     ]
    }
   ],
   "source": [
    "# Convert 'Date' column to datetime format in both DataFrames\n",
    "live_sentiments_df['Date'] = pd.to_datetime(live_sentiments_df['Date'])\n",
    "historical_news_df['Date'] = pd.to_datetime(historical_news_df['Date'])\n",
    "\n",
    "# Merge the DataFrames and sort by 'Date'\n",
    "sentiment_df = pd.concat([live_sentiments_df, historical_news_df], ignore_index=True).sort_values(by='Date')\n",
    "\n",
    "# Display the first few rows\n",
    "print(sentiment_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "716ed45f-06e9-4a89-9fbc-f1940c726ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "commodity_data['Date'] = pd.to_datetime(commodity_data['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "202f7dfc-27af-49d7-9f5c-475c55231d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>GDP</th>\n",
       "      <th>Interest_rates</th>\n",
       "      <th>Inflation_rate</th>\n",
       "      <th>DebtToGDP</th>\n",
       "      <th>ETF_Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2588</th>\n",
       "      <td>2025-04-21</td>\n",
       "      <td>64.300003</td>\n",
       "      <td>64.419998</td>\n",
       "      <td>62.450001</td>\n",
       "      <td>63.080002</td>\n",
       "      <td>82671</td>\n",
       "      <td>2.195852e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>105.457564</td>\n",
       "      <td>1.377451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2589</th>\n",
       "      <td>2025-04-22</td>\n",
       "      <td>63.430000</td>\n",
       "      <td>65.089996</td>\n",
       "      <td>63.430000</td>\n",
       "      <td>64.309998</td>\n",
       "      <td>297928</td>\n",
       "      <td>2.195852e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>105.457564</td>\n",
       "      <td>1.377451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2590</th>\n",
       "      <td>2025-04-23</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>64.870003</td>\n",
       "      <td>61.529999</td>\n",
       "      <td>62.270000</td>\n",
       "      <td>397841</td>\n",
       "      <td>2.195852e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>105.457564</td>\n",
       "      <td>1.377451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2591</th>\n",
       "      <td>2025-04-24</td>\n",
       "      <td>62.340000</td>\n",
       "      <td>63.310001</td>\n",
       "      <td>61.990002</td>\n",
       "      <td>62.790001</td>\n",
       "      <td>264908</td>\n",
       "      <td>2.195852e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>105.457564</td>\n",
       "      <td>1.377451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2592</th>\n",
       "      <td>2025-04-25</td>\n",
       "      <td>62.860001</td>\n",
       "      <td>63.410000</td>\n",
       "      <td>61.799999</td>\n",
       "      <td>63.020000</td>\n",
       "      <td>283758</td>\n",
       "      <td>2.195852e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>105.457564</td>\n",
       "      <td>1.377451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date       Open       High        Low      Close  Volume  \\\n",
       "2588 2025-04-21  64.300003  64.419998  62.450001  63.080002   82671   \n",
       "2589 2025-04-22  63.430000  65.089996  63.430000  64.309998  297928   \n",
       "2590 2025-04-23  64.000000  64.870003  61.529999  62.270000  397841   \n",
       "2591 2025-04-24  62.340000  63.310001  61.990002  62.790001  264908   \n",
       "2592 2025-04-25  62.860001  63.410000  61.799999  63.020000  283758   \n",
       "\n",
       "               GDP  Interest_rates  Inflation_rate   DebtToGDP  ETF_Value  \n",
       "2588  2.195852e+13        1.815679        1.815679  105.457564   1.377451  \n",
       "2589  2.195852e+13        1.815679        1.815679  105.457564   1.377451  \n",
       "2590  2.195852e+13        1.815679        1.815679  105.457564   1.377451  \n",
       "2591  2.195852e+13        1.815679        1.815679  105.457564   1.377451  \n",
       "2592  2.195852e+13        1.815679        1.815679  105.457564   1.377451  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commodity_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce208bad-a430-4f82-adaa-b677d03b8d79",
   "metadata": {},
   "source": [
    "### 2.8 Merging Sentiment Data with Gold Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6b3e5497-3e92-4761-930e-00ce61374195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>GDP</th>\n",
       "      <th>Interest_rates</th>\n",
       "      <th>Inflation_rate</th>\n",
       "      <th>DebtToGDP</th>\n",
       "      <th>ETF_Value</th>\n",
       "      <th>Sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>53.759998</td>\n",
       "      <td>55.110001</td>\n",
       "      <td>52.029999</td>\n",
       "      <td>52.689999</td>\n",
       "      <td>268708</td>\n",
       "      <td>1.829502e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>95.956145</td>\n",
       "      <td>1.377451</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>52.610001</td>\n",
       "      <td>52.730000</td>\n",
       "      <td>49.680000</td>\n",
       "      <td>50.040001</td>\n",
       "      <td>375782</td>\n",
       "      <td>1.829502e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>95.956145</td>\n",
       "      <td>1.377451</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.369999</td>\n",
       "      <td>47.549999</td>\n",
       "      <td>47.930000</td>\n",
       "      <td>451642</td>\n",
       "      <td>1.829502e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>95.956145</td>\n",
       "      <td>1.377451</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-07</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>49.310001</td>\n",
       "      <td>46.830002</td>\n",
       "      <td>48.650002</td>\n",
       "      <td>460083</td>\n",
       "      <td>1.829502e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>95.956145</td>\n",
       "      <td>1.377451</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>48.779999</td>\n",
       "      <td>49.650002</td>\n",
       "      <td>47.730000</td>\n",
       "      <td>48.790001</td>\n",
       "      <td>362081</td>\n",
       "      <td>1.829502e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>95.956145</td>\n",
       "      <td>1.377451</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date       Open       High        Low      Close  Volume  \\\n",
       "0 2015-01-02  53.759998  55.110001  52.029999  52.689999  268708   \n",
       "1 2015-01-05  52.610001  52.730000  49.680000  50.040001  375782   \n",
       "2 2015-01-06  50.000000  50.369999  47.549999  47.930000  451642   \n",
       "3 2015-01-07  48.000000  49.310001  46.830002  48.650002  460083   \n",
       "4 2015-01-08  48.779999  49.650002  47.730000  48.790001  362081   \n",
       "\n",
       "            GDP  Interest_rates  Inflation_rate  DebtToGDP  ETF_Value  \\\n",
       "0  1.829502e+13        1.815679        1.815679  95.956145   1.377451   \n",
       "1  1.829502e+13        1.815679        1.815679  95.956145   1.377451   \n",
       "2  1.829502e+13        1.815679        1.815679  95.956145   1.377451   \n",
       "3  1.829502e+13        1.815679        1.815679  95.956145   1.377451   \n",
       "4  1.829502e+13        1.815679        1.815679  95.956145   1.377451   \n",
       "\n",
       "   Sentiment_score  \n",
       "0              NaN  \n",
       "1              NaN  \n",
       "2              NaN  \n",
       "3              NaN  \n",
       "4              NaN  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commodity_data = pd.merge(commodity_data, sentiment_df[['Date', 'Sentiment_score']], on='Date', how='left')\n",
    "commodity_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "014e550d-355e-4a9f-89fc-b5dd049669ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment_score\n",
       "-1.0    55\n",
       " 0.0    41\n",
       " 1.0    25\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commodity_data['Sentiment_score'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48bbf16-b900-4d6b-80e2-b86329b9aee4",
   "metadata": {},
   "source": [
    "### 2.9 Null Treatment post sentiment merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fe6db6d5-5994-4a96-b6d2-fc9d35d89a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date               0\n",
      "Open               0\n",
      "High               0\n",
      "Low                0\n",
      "Close              0\n",
      "Volume             0\n",
      "GDP                0\n",
      "Interest_rates     0\n",
      "Inflation_rate     0\n",
      "DebtToGDP          0\n",
      "ETF_Value          0\n",
      "Sentiment_score    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_28728\\1915627315.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  commodity_data['Sentiment_score'].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#Interpolation – Estimate Sentiment Values Based on Nearby Data\n",
    "#Good for gradual sentiment changes but may not capture sudden shifts.\n",
    "commodity_data['Sentiment_score'] = sentiment_df['Sentiment_score'].interpolate(method='linear')  \n",
    "\n",
    "commodity_data['Sentiment_score'].fillna(0, inplace=True)\n",
    "# Print summary of missing values after imputation\n",
    "print(commodity_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a17ec0e4-14dc-4daa-a785-23c30807c9a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment_score\n",
       " 0.0    2194\n",
       "-1.0     286\n",
       " 1.0     224\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commodity_data['Sentiment_score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8b0b9652-9fde-491a-879d-b02c76a40d5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>GDP</th>\n",
       "      <th>Interest_rates</th>\n",
       "      <th>Inflation_rate</th>\n",
       "      <th>DebtToGDP</th>\n",
       "      <th>ETF_Value</th>\n",
       "      <th>Sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>53.759998</td>\n",
       "      <td>55.110001</td>\n",
       "      <td>52.029999</td>\n",
       "      <td>52.689999</td>\n",
       "      <td>268708</td>\n",
       "      <td>1.829502e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>95.956145</td>\n",
       "      <td>1.377451</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>52.610001</td>\n",
       "      <td>52.730000</td>\n",
       "      <td>49.680000</td>\n",
       "      <td>50.040001</td>\n",
       "      <td>375782</td>\n",
       "      <td>1.829502e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>95.956145</td>\n",
       "      <td>1.377451</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.369999</td>\n",
       "      <td>47.549999</td>\n",
       "      <td>47.930000</td>\n",
       "      <td>451642</td>\n",
       "      <td>1.829502e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>95.956145</td>\n",
       "      <td>1.377451</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-07</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>49.310001</td>\n",
       "      <td>46.830002</td>\n",
       "      <td>48.650002</td>\n",
       "      <td>460083</td>\n",
       "      <td>1.829502e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>95.956145</td>\n",
       "      <td>1.377451</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>48.779999</td>\n",
       "      <td>49.650002</td>\n",
       "      <td>47.730000</td>\n",
       "      <td>48.790001</td>\n",
       "      <td>362081</td>\n",
       "      <td>1.829502e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>95.956145</td>\n",
       "      <td>1.377451</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2699</th>\n",
       "      <td>2025-04-25</td>\n",
       "      <td>62.860001</td>\n",
       "      <td>63.410000</td>\n",
       "      <td>61.799999</td>\n",
       "      <td>63.020000</td>\n",
       "      <td>283758</td>\n",
       "      <td>2.195852e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>105.457564</td>\n",
       "      <td>1.377451</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2700</th>\n",
       "      <td>2025-04-25</td>\n",
       "      <td>62.860001</td>\n",
       "      <td>63.410000</td>\n",
       "      <td>61.799999</td>\n",
       "      <td>63.020000</td>\n",
       "      <td>283758</td>\n",
       "      <td>2.195852e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>105.457564</td>\n",
       "      <td>1.377451</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2701</th>\n",
       "      <td>2025-04-25</td>\n",
       "      <td>62.860001</td>\n",
       "      <td>63.410000</td>\n",
       "      <td>61.799999</td>\n",
       "      <td>63.020000</td>\n",
       "      <td>283758</td>\n",
       "      <td>2.195852e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>105.457564</td>\n",
       "      <td>1.377451</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2702</th>\n",
       "      <td>2025-04-25</td>\n",
       "      <td>62.860001</td>\n",
       "      <td>63.410000</td>\n",
       "      <td>61.799999</td>\n",
       "      <td>63.020000</td>\n",
       "      <td>283758</td>\n",
       "      <td>2.195852e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>105.457564</td>\n",
       "      <td>1.377451</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2703</th>\n",
       "      <td>2025-04-25</td>\n",
       "      <td>62.860001</td>\n",
       "      <td>63.410000</td>\n",
       "      <td>61.799999</td>\n",
       "      <td>63.020000</td>\n",
       "      <td>283758</td>\n",
       "      <td>2.195852e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>105.457564</td>\n",
       "      <td>1.377451</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2704 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date       Open       High        Low      Close  Volume  \\\n",
       "0    2015-01-02  53.759998  55.110001  52.029999  52.689999  268708   \n",
       "1    2015-01-05  52.610001  52.730000  49.680000  50.040001  375782   \n",
       "2    2015-01-06  50.000000  50.369999  47.549999  47.930000  451642   \n",
       "3    2015-01-07  48.000000  49.310001  46.830002  48.650002  460083   \n",
       "4    2015-01-08  48.779999  49.650002  47.730000  48.790001  362081   \n",
       "...         ...        ...        ...        ...        ...     ...   \n",
       "2699 2025-04-25  62.860001  63.410000  61.799999  63.020000  283758   \n",
       "2700 2025-04-25  62.860001  63.410000  61.799999  63.020000  283758   \n",
       "2701 2025-04-25  62.860001  63.410000  61.799999  63.020000  283758   \n",
       "2702 2025-04-25  62.860001  63.410000  61.799999  63.020000  283758   \n",
       "2703 2025-04-25  62.860001  63.410000  61.799999  63.020000  283758   \n",
       "\n",
       "               GDP  Interest_rates  Inflation_rate   DebtToGDP  ETF_Value  \\\n",
       "0     1.829502e+13        1.815679        1.815679   95.956145   1.377451   \n",
       "1     1.829502e+13        1.815679        1.815679   95.956145   1.377451   \n",
       "2     1.829502e+13        1.815679        1.815679   95.956145   1.377451   \n",
       "3     1.829502e+13        1.815679        1.815679   95.956145   1.377451   \n",
       "4     1.829502e+13        1.815679        1.815679   95.956145   1.377451   \n",
       "...            ...             ...             ...         ...        ...   \n",
       "2699  2.195852e+13        1.815679        1.815679  105.457564   1.377451   \n",
       "2700  2.195852e+13        1.815679        1.815679  105.457564   1.377451   \n",
       "2701  2.195852e+13        1.815679        1.815679  105.457564   1.377451   \n",
       "2702  2.195852e+13        1.815679        1.815679  105.457564   1.377451   \n",
       "2703  2.195852e+13        1.815679        1.815679  105.457564   1.377451   \n",
       "\n",
       "      Sentiment_score  \n",
       "0                 0.0  \n",
       "1                -1.0  \n",
       "2                 0.0  \n",
       "3                -1.0  \n",
       "4                 0.0  \n",
       "...               ...  \n",
       "2699              0.0  \n",
       "2700              0.0  \n",
       "2701              0.0  \n",
       "2702              0.0  \n",
       "2703              0.0  \n",
       "\n",
       "[2704 rows x 12 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commodity_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae02e881-de27-4fad-9de3-0e4a209018be",
   "metadata": {},
   "source": [
    "## Step 3 : Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9437eab3-4c66-484a-b4e7-4c991396d51d",
   "metadata": {},
   "source": [
    "### 4.1 Create Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0b28f4de-4d34-450f-b229-ae25e6d5c7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def feature_engineering(df, world_bank_data=None):\n",
    "    # Lagged values and moving averages\n",
    "    df['lag_1'] = df['Close'].shift(1)\n",
    "    df['lag_7'] = df['Close'].shift(7)\n",
    "    df['lag_30'] = df['Close'].shift(30)\n",
    "    df['MA_7'] = df['Close'].rolling(window=7).mean()\n",
    "    df['MA_30'] = df['Close'].rolling(window=30).mean()\n",
    "    df['MA_90'] = df['Close'].rolling(window=90).mean()\n",
    "    df['tomorrow_price'] = df['Close'].shift(-1)\n",
    "    # Compute log returns fro GARCH\n",
    "    df['Log_Returns'] = np.log(df['Close'] / df['Close'].shift(1))\n",
    "\n",
    "    # Adding volatility features\n",
    "    df['volatility_7'] = df['Close'].rolling(window=7).std()\n",
    "    df['volatility_30'] = df['Close'].rolling(window=30).std()\n",
    "\n",
    "    # #Gold prices may respond more to cumulative sentiment trends rather than individual daily sentiments. We apply a moving average to smooth fluctuations.\n",
    "    # # Creating lagged sentiment features\n",
    "    # df[\"Sentiment_Lag_1\"] = df[\"Sentiment_score\"].shift(1)\n",
    "    # df[\"Sentiment_Lag_3\"] = df[\"Sentiment_score\"].shift(3)\n",
    "    # df[\"Sentiment_Lag_7\"] = df[\"Sentiment_score\"].shift(7)\n",
    "    # Compute rolling mean sentiment over 14-day and 30-day windows\n",
    "    df[\"Sentiment_Rolling_14\"] = df[\"Sentiment_score\"].rolling(window=14, min_periods=1).mean()\n",
    "    df[\"Sentiment_Rolling_30\"] = df[\"Sentiment_score\"].rolling(window=30, min_periods=1).mean()\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157679fd-25f6-4d80-a363-df324462c509",
   "metadata": {},
   "source": [
    "### 4.2 Apply Feature engineering on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2bded4d6-6b3c-4c2f-bceb-d1ca6cd7cfe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\myvenv\\myenv\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "commodity_data = feature_engineering(commodity_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aae9fcef-cdde-4328-be3a-83a91cc2f54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\myvenv\\myenv\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>GDP</th>\n",
       "      <th>Interest_rates</th>\n",
       "      <th>Inflation_rate</th>\n",
       "      <th>DebtToGDP</th>\n",
       "      <th>...</th>\n",
       "      <th>lag_30</th>\n",
       "      <th>MA_7</th>\n",
       "      <th>MA_30</th>\n",
       "      <th>MA_90</th>\n",
       "      <th>tomorrow_price</th>\n",
       "      <th>Log_Returns</th>\n",
       "      <th>volatility_7</th>\n",
       "      <th>volatility_30</th>\n",
       "      <th>Sentiment_Rolling_14</th>\n",
       "      <th>Sentiment_Rolling_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>53.759998</td>\n",
       "      <td>55.110001</td>\n",
       "      <td>52.029999</td>\n",
       "      <td>52.689999</td>\n",
       "      <td>268708</td>\n",
       "      <td>1.829502e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>95.956145</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.040001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>52.610001</td>\n",
       "      <td>52.730000</td>\n",
       "      <td>49.680000</td>\n",
       "      <td>50.040001</td>\n",
       "      <td>375782</td>\n",
       "      <td>1.829502e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>95.956145</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.930000</td>\n",
       "      <td>-0.051603</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.369999</td>\n",
       "      <td>47.549999</td>\n",
       "      <td>47.930000</td>\n",
       "      <td>451642</td>\n",
       "      <td>1.829502e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>95.956145</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.650002</td>\n",
       "      <td>-0.043081</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-07</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>49.310001</td>\n",
       "      <td>46.830002</td>\n",
       "      <td>48.650002</td>\n",
       "      <td>460083</td>\n",
       "      <td>1.829502e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>95.956145</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.790001</td>\n",
       "      <td>0.014910</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>48.779999</td>\n",
       "      <td>49.650002</td>\n",
       "      <td>47.730000</td>\n",
       "      <td>48.790001</td>\n",
       "      <td>362081</td>\n",
       "      <td>1.829502e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>95.956145</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.360001</td>\n",
       "      <td>0.002874</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>-0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2699</th>\n",
       "      <td>2025-04-25</td>\n",
       "      <td>62.860001</td>\n",
       "      <td>63.410000</td>\n",
       "      <td>61.799999</td>\n",
       "      <td>63.020000</td>\n",
       "      <td>283758</td>\n",
       "      <td>2.195852e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>105.457564</td>\n",
       "      <td>...</td>\n",
       "      <td>63.02</td>\n",
       "      <td>63.02</td>\n",
       "      <td>63.02</td>\n",
       "      <td>62.892445</td>\n",
       "      <td>63.020000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2700</th>\n",
       "      <td>2025-04-25</td>\n",
       "      <td>62.860001</td>\n",
       "      <td>63.410000</td>\n",
       "      <td>61.799999</td>\n",
       "      <td>63.020000</td>\n",
       "      <td>283758</td>\n",
       "      <td>2.195852e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>105.457564</td>\n",
       "      <td>...</td>\n",
       "      <td>63.02</td>\n",
       "      <td>63.02</td>\n",
       "      <td>63.02</td>\n",
       "      <td>62.878112</td>\n",
       "      <td>63.020000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2701</th>\n",
       "      <td>2025-04-25</td>\n",
       "      <td>62.860001</td>\n",
       "      <td>63.410000</td>\n",
       "      <td>61.799999</td>\n",
       "      <td>63.020000</td>\n",
       "      <td>283758</td>\n",
       "      <td>2.195852e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>105.457564</td>\n",
       "      <td>...</td>\n",
       "      <td>63.02</td>\n",
       "      <td>63.02</td>\n",
       "      <td>63.02</td>\n",
       "      <td>62.863778</td>\n",
       "      <td>63.020000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2702</th>\n",
       "      <td>2025-04-25</td>\n",
       "      <td>62.860001</td>\n",
       "      <td>63.410000</td>\n",
       "      <td>61.799999</td>\n",
       "      <td>63.020000</td>\n",
       "      <td>283758</td>\n",
       "      <td>2.195852e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>105.457564</td>\n",
       "      <td>...</td>\n",
       "      <td>63.02</td>\n",
       "      <td>63.02</td>\n",
       "      <td>63.02</td>\n",
       "      <td>62.872112</td>\n",
       "      <td>63.020000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2703</th>\n",
       "      <td>2025-04-25</td>\n",
       "      <td>62.860001</td>\n",
       "      <td>63.410000</td>\n",
       "      <td>61.799999</td>\n",
       "      <td>63.020000</td>\n",
       "      <td>283758</td>\n",
       "      <td>2.195852e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>105.457564</td>\n",
       "      <td>...</td>\n",
       "      <td>63.02</td>\n",
       "      <td>63.02</td>\n",
       "      <td>63.02</td>\n",
       "      <td>62.880445</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2704 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date       Open       High        Low      Close  Volume  \\\n",
       "0    2015-01-02  53.759998  55.110001  52.029999  52.689999  268708   \n",
       "1    2015-01-05  52.610001  52.730000  49.680000  50.040001  375782   \n",
       "2    2015-01-06  50.000000  50.369999  47.549999  47.930000  451642   \n",
       "3    2015-01-07  48.000000  49.310001  46.830002  48.650002  460083   \n",
       "4    2015-01-08  48.779999  49.650002  47.730000  48.790001  362081   \n",
       "...         ...        ...        ...        ...        ...     ...   \n",
       "2699 2025-04-25  62.860001  63.410000  61.799999  63.020000  283758   \n",
       "2700 2025-04-25  62.860001  63.410000  61.799999  63.020000  283758   \n",
       "2701 2025-04-25  62.860001  63.410000  61.799999  63.020000  283758   \n",
       "2702 2025-04-25  62.860001  63.410000  61.799999  63.020000  283758   \n",
       "2703 2025-04-25  62.860001  63.410000  61.799999  63.020000  283758   \n",
       "\n",
       "               GDP  Interest_rates  Inflation_rate   DebtToGDP  ...  lag_30  \\\n",
       "0     1.829502e+13        1.815679        1.815679   95.956145  ...     NaN   \n",
       "1     1.829502e+13        1.815679        1.815679   95.956145  ...     NaN   \n",
       "2     1.829502e+13        1.815679        1.815679   95.956145  ...     NaN   \n",
       "3     1.829502e+13        1.815679        1.815679   95.956145  ...     NaN   \n",
       "4     1.829502e+13        1.815679        1.815679   95.956145  ...     NaN   \n",
       "...            ...             ...             ...         ...  ...     ...   \n",
       "2699  2.195852e+13        1.815679        1.815679  105.457564  ...   63.02   \n",
       "2700  2.195852e+13        1.815679        1.815679  105.457564  ...   63.02   \n",
       "2701  2.195852e+13        1.815679        1.815679  105.457564  ...   63.02   \n",
       "2702  2.195852e+13        1.815679        1.815679  105.457564  ...   63.02   \n",
       "2703  2.195852e+13        1.815679        1.815679  105.457564  ...   63.02   \n",
       "\n",
       "       MA_7  MA_30      MA_90  tomorrow_price  Log_Returns  volatility_7  \\\n",
       "0       NaN    NaN        NaN       50.040001          NaN           NaN   \n",
       "1       NaN    NaN        NaN       47.930000    -0.051603           NaN   \n",
       "2       NaN    NaN        NaN       48.650002    -0.043081           NaN   \n",
       "3       NaN    NaN        NaN       48.790001     0.014910           NaN   \n",
       "4       NaN    NaN        NaN       48.360001     0.002874           NaN   \n",
       "...     ...    ...        ...             ...          ...           ...   \n",
       "2699  63.02  63.02  62.892445       63.020000     0.000000           0.0   \n",
       "2700  63.02  63.02  62.878112       63.020000     0.000000           0.0   \n",
       "2701  63.02  63.02  62.863778       63.020000     0.000000           0.0   \n",
       "2702  63.02  63.02  62.872112       63.020000     0.000000           0.0   \n",
       "2703  63.02  63.02  62.880445             NaN     0.000000           0.0   \n",
       "\n",
       "      volatility_30  Sentiment_Rolling_14  Sentiment_Rolling_30  \n",
       "0               NaN              0.000000              0.000000  \n",
       "1               NaN             -0.500000             -0.500000  \n",
       "2               NaN             -0.333333             -0.333333  \n",
       "3               NaN             -0.500000             -0.500000  \n",
       "4               NaN             -0.400000             -0.400000  \n",
       "...             ...                   ...                   ...  \n",
       "2699            0.0              0.000000              0.000000  \n",
       "2700            0.0              0.000000              0.000000  \n",
       "2701            0.0              0.000000              0.000000  \n",
       "2702            0.0              0.000000              0.000000  \n",
       "2703            0.0              0.000000              0.000000  \n",
       "\n",
       "[2704 rows x 24 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_engineering(commodity_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5b6a4df5-7e2c-48ec-951c-25b8a4093f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Close</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Low</th>\n",
       "      <td>0.998174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>High</th>\n",
       "      <td>0.996196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Open</th>\n",
       "      <td>0.994270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lag_1</th>\n",
       "      <td>0.992844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tomorrow_price</th>\n",
       "      <td>0.992844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MA_7</th>\n",
       "      <td>0.991606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lag_7</th>\n",
       "      <td>0.971665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MA_30</th>\n",
       "      <td>0.965869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MA_90</th>\n",
       "      <td>0.899961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lag_30</th>\n",
       "      <td>0.894548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <td>0.616589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GDP</th>\n",
       "      <td>0.179367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>volatility_7</th>\n",
       "      <td>0.133393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>volatility_30</th>\n",
       "      <td>0.130410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentiment_Rolling_30</th>\n",
       "      <td>0.117906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DebtToGDP</th>\n",
       "      <td>0.098018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Inflation_rate</th>\n",
       "      <td>0.092438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Interest_rates</th>\n",
       "      <td>0.092438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentiment_Rolling_14</th>\n",
       "      <td>0.079231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ETF_Value</th>\n",
       "      <td>0.046228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentiment_score</th>\n",
       "      <td>0.024648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Log_Returns</th>\n",
       "      <td>0.016442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Volume</th>\n",
       "      <td>-0.338564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Correlation\n",
       "Close                    1.000000\n",
       "Low                      0.998174\n",
       "High                     0.996196\n",
       "Open                     0.994270\n",
       "lag_1                    0.992844\n",
       "tomorrow_price           0.992844\n",
       "MA_7                     0.991606\n",
       "lag_7                    0.971665\n",
       "MA_30                    0.965869\n",
       "MA_90                    0.899961\n",
       "lag_30                   0.894548\n",
       "Date                     0.616589\n",
       "GDP                      0.179367\n",
       "volatility_7             0.133393\n",
       "volatility_30            0.130410\n",
       "Sentiment_Rolling_30     0.117906\n",
       "DebtToGDP                0.098018\n",
       "Inflation_rate           0.092438\n",
       "Interest_rates           0.092438\n",
       "Sentiment_Rolling_14     0.079231\n",
       "ETF_Value                0.046228\n",
       "Sentiment_score          0.024648\n",
       "Log_Returns              0.016442\n",
       "Volume                  -0.338564"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compute correlation of all features with 'Close'\n",
    "correlation_with_close = commodity_data.corr()[\"Close\"].sort_values(ascending=False)\n",
    "\n",
    "# Convert to DataFrame\n",
    "correlation_df = correlation_with_close.to_frame().rename(columns={\"Close\": \"Correlation\"})\n",
    "\n",
    "correlation_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd49b4c-9ce0-465f-b6a8-0f9bdc0259ec",
   "metadata": {},
   "source": [
    "### 4.3 Seting Index of data frame is as a Date column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "395ea7c4-58e6-4ea2-a894-dfdcad0d5e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "commodity_data_df = commodity_data\n",
    "commodity_data_df.set_index('Date', drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e7d53386-1c67-45a5-80f7-632ec67c61cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>GDP</th>\n",
       "      <th>Interest_rates</th>\n",
       "      <th>Inflation_rate</th>\n",
       "      <th>DebtToGDP</th>\n",
       "      <th>ETF_Value</th>\n",
       "      <th>...</th>\n",
       "      <th>lag_30</th>\n",
       "      <th>MA_7</th>\n",
       "      <th>MA_30</th>\n",
       "      <th>MA_90</th>\n",
       "      <th>tomorrow_price</th>\n",
       "      <th>Log_Returns</th>\n",
       "      <th>volatility_7</th>\n",
       "      <th>volatility_30</th>\n",
       "      <th>Sentiment_Rolling_14</th>\n",
       "      <th>Sentiment_Rolling_30</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-04-25</th>\n",
       "      <td>62.860001</td>\n",
       "      <td>63.41</td>\n",
       "      <td>61.799999</td>\n",
       "      <td>63.02</td>\n",
       "      <td>283758</td>\n",
       "      <td>2.195852e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>105.457564</td>\n",
       "      <td>1.377451</td>\n",
       "      <td>...</td>\n",
       "      <td>63.02</td>\n",
       "      <td>63.02</td>\n",
       "      <td>63.02</td>\n",
       "      <td>62.892445</td>\n",
       "      <td>63.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-25</th>\n",
       "      <td>62.860001</td>\n",
       "      <td>63.41</td>\n",
       "      <td>61.799999</td>\n",
       "      <td>63.02</td>\n",
       "      <td>283758</td>\n",
       "      <td>2.195852e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>105.457564</td>\n",
       "      <td>1.377451</td>\n",
       "      <td>...</td>\n",
       "      <td>63.02</td>\n",
       "      <td>63.02</td>\n",
       "      <td>63.02</td>\n",
       "      <td>62.878112</td>\n",
       "      <td>63.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-25</th>\n",
       "      <td>62.860001</td>\n",
       "      <td>63.41</td>\n",
       "      <td>61.799999</td>\n",
       "      <td>63.02</td>\n",
       "      <td>283758</td>\n",
       "      <td>2.195852e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>105.457564</td>\n",
       "      <td>1.377451</td>\n",
       "      <td>...</td>\n",
       "      <td>63.02</td>\n",
       "      <td>63.02</td>\n",
       "      <td>63.02</td>\n",
       "      <td>62.863778</td>\n",
       "      <td>63.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-25</th>\n",
       "      <td>62.860001</td>\n",
       "      <td>63.41</td>\n",
       "      <td>61.799999</td>\n",
       "      <td>63.02</td>\n",
       "      <td>283758</td>\n",
       "      <td>2.195852e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>105.457564</td>\n",
       "      <td>1.377451</td>\n",
       "      <td>...</td>\n",
       "      <td>63.02</td>\n",
       "      <td>63.02</td>\n",
       "      <td>63.02</td>\n",
       "      <td>62.872112</td>\n",
       "      <td>63.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-25</th>\n",
       "      <td>62.860001</td>\n",
       "      <td>63.41</td>\n",
       "      <td>61.799999</td>\n",
       "      <td>63.02</td>\n",
       "      <td>283758</td>\n",
       "      <td>2.195852e+13</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>1.815679</td>\n",
       "      <td>105.457564</td>\n",
       "      <td>1.377451</td>\n",
       "      <td>...</td>\n",
       "      <td>63.02</td>\n",
       "      <td>63.02</td>\n",
       "      <td>63.02</td>\n",
       "      <td>62.880445</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Open   High        Low  Close  Volume           GDP  \\\n",
       "Date                                                                   \n",
       "2025-04-25  62.860001  63.41  61.799999  63.02  283758  2.195852e+13   \n",
       "2025-04-25  62.860001  63.41  61.799999  63.02  283758  2.195852e+13   \n",
       "2025-04-25  62.860001  63.41  61.799999  63.02  283758  2.195852e+13   \n",
       "2025-04-25  62.860001  63.41  61.799999  63.02  283758  2.195852e+13   \n",
       "2025-04-25  62.860001  63.41  61.799999  63.02  283758  2.195852e+13   \n",
       "\n",
       "            Interest_rates  Inflation_rate   DebtToGDP  ETF_Value  ...  \\\n",
       "Date                                                               ...   \n",
       "2025-04-25        1.815679        1.815679  105.457564   1.377451  ...   \n",
       "2025-04-25        1.815679        1.815679  105.457564   1.377451  ...   \n",
       "2025-04-25        1.815679        1.815679  105.457564   1.377451  ...   \n",
       "2025-04-25        1.815679        1.815679  105.457564   1.377451  ...   \n",
       "2025-04-25        1.815679        1.815679  105.457564   1.377451  ...   \n",
       "\n",
       "            lag_30   MA_7  MA_30      MA_90  tomorrow_price  Log_Returns  \\\n",
       "Date                                                                       \n",
       "2025-04-25   63.02  63.02  63.02  62.892445           63.02          0.0   \n",
       "2025-04-25   63.02  63.02  63.02  62.878112           63.02          0.0   \n",
       "2025-04-25   63.02  63.02  63.02  62.863778           63.02          0.0   \n",
       "2025-04-25   63.02  63.02  63.02  62.872112           63.02          0.0   \n",
       "2025-04-25   63.02  63.02  63.02  62.880445             NaN          0.0   \n",
       "\n",
       "            volatility_7  volatility_30  Sentiment_Rolling_14  \\\n",
       "Date                                                            \n",
       "2025-04-25           0.0            0.0                   0.0   \n",
       "2025-04-25           0.0            0.0                   0.0   \n",
       "2025-04-25           0.0            0.0                   0.0   \n",
       "2025-04-25           0.0            0.0                   0.0   \n",
       "2025-04-25           0.0            0.0                   0.0   \n",
       "\n",
       "            Sentiment_Rolling_30  \n",
       "Date                              \n",
       "2025-04-25                   0.0  \n",
       "2025-04-25                   0.0  \n",
       "2025-04-25                   0.0  \n",
       "2025-04-25                   0.0  \n",
       "2025-04-25                   0.0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commodity_data_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be330a1c-1540-407f-876e-c00977c51d43",
   "metadata": {},
   "source": [
    "### Step 5 Data Split and Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1047ca42-6c7e-4bea-a404-bc33edb096ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (2164, 23), Test size: (541, 23)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert index to datetime if not already\n",
    "commodity_data_df.index = pd.to_datetime(commodity_data_df.index)\n",
    "\n",
    "# Define 80-20% split based on row count\n",
    "split_index = int(len(commodity_data_df) * 0.80) \n",
    "# split_date =  pd.to_datetime('2022-01-01')\n",
    "split_date = commodity_data_df.index[split_index]  \n",
    "\n",
    "# Train-test split\n",
    "train_df = commodity_data_df.loc[:split_date]  \n",
    "test_df = commodity_data_df.loc[split_date:]\n",
    "\n",
    "print(f\"Train size: {train_df.shape}, Test size: {test_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "aad8f244-64a3-4f97-8d2c-e7b26678b10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "\n",
    "# Select features and target\n",
    "X_train = train_df.drop(columns=['tomorrow_price', 'Close' ])\n",
    "y_train = train_df['Close']\n",
    "X_test = test_df.drop(columns=['tomorrow_price', 'Close'])\n",
    "y_test = test_df['Close']\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dba8efe4-e10a-4e92-b76c-b8d5f4d5f3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# Define scalers\n",
    "scaler_minmax = MinMaxScaler()  # For XGBoost, Random Forest\n",
    "scaler_standard = StandardScaler()  # For LSTM\n",
    "\n",
    "# Apply MinMax Scaling (for tree-based models)\n",
    "X_train_scaled_minmax = scaler_minmax.fit_transform(X_train)\n",
    "X_test_scaled_minmax = scaler_minmax.transform(X_test)\n",
    "\n",
    "# Apply Standard Scaling (for LSTM)\n",
    "X_train_scaled_standard = scaler_standard.fit_transform(X_train)\n",
    "X_test_scaled_standard = scaler_standard.transform(X_test)\n",
    "\n",
    "\n",
    "# # Rescale y_train\n",
    "# scaler_y = MinMaxScaler()\n",
    "y_train_scaled = scaler_minmax.fit_transform(y_train.values.reshape(-1, 1)).ravel()\n",
    "y_test_scaled = scaler_minmax.transform(y_test.values.reshape(-1, 1)).ravel()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d621cef0-f0b8-45e6-932a-5b34c260f416",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 8.1 Load pre trained model from File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "35bd063f-38c5-40bf-bdc6-4eacb1521288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting using model: RF_best-2\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\myvenv\\myenv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values: [83.45233267 82.98618685 82.51070919 81.3807724  79.81846808 80.61652878\n",
      " 80.91268035 81.44815822 81.07887779 78.40811046 78.67438619 79.71507661\n",
      " 80.63538649 80.88292531 81.79464213 83.26167015 85.1747142  87.08077107\n",
      " 87.46360192 86.85756298 87.27945777 88.19653261 88.59313742 88.52335985\n",
      " 89.80267064 89.98168933 91.28935539 92.26914536 89.88330411 89.87822907\n",
      " 90.14013458 89.93991001 89.84022266 92.91992778 92.76340473 91.71511757\n",
      " 89.55978439 89.40490838 85.96733801 82.94546692 82.55963819 86.68405534\n",
      " 85.62739782 85.08173613 82.92106915 86.72361005 86.97510802 86.61132108\n",
      " 88.81546517 89.40383081 89.37913341 86.33806182 85.03954988 84.00293108\n",
      " 83.58166614 85.30581401 82.43323699 81.78940834 81.33658244 81.55876987\n",
      " 81.3728188  81.49432722 78.06308902 76.08677493 76.39755909 77.11524922\n",
      " 78.24533052 78.74654799 76.99007402 73.36354435 74.7313728  77.53823168\n",
      " 76.97712145 74.80530292 75.83733732 75.02524416 76.51238855 77.2801406\n",
      " 76.62871907 74.88448908 73.28993851 72.66262798 70.24926014 69.77699824\n",
      " 71.09526991 71.14730972 68.64914226 69.3462572  71.63905241 71.52953795\n",
      " 72.79991697 73.27742717 74.87213358 73.43933968 74.16449277 75.16727133\n",
      " 74.48923582 72.18450487 71.85143584 71.06896647 72.23607021 71.9216931\n",
      " 74.0819447  71.13307931 72.14565033 71.81967189 72.96658804 73.89712687\n",
      " 72.03937815 71.75277755 74.14771249 73.96075497 74.78916974 74.05824148\n",
      " 75.23075754 77.00741302 77.29862952 77.69239846 77.18050954 76.08172946\n",
      " 74.4498421  72.17507212 72.65541833 73.62937849 74.37926954 75.39414776\n",
      " 76.66387146 75.74081988 78.20377471 77.56618018 78.02942064 78.85355115\n",
      " 78.50336034 76.48301658 78.45884967 76.86102869 77.15655731 78.5393872\n",
      " 78.61382864 78.69094314 79.96394353 79.22331411 78.57867813 79.83476267\n",
      " 78.77267418 78.7179999  78.16260421 78.4106408  79.32511771 80.77858914\n",
      " 81.16269144 82.51589207 83.61719341 82.05327655 81.13507657 81.21145682\n",
      " 81.93337303 81.79661715 81.42961308 82.94301906 84.25578152 85.10607288\n",
      " 85.36450274 86.54949807 86.90133741 86.08575755 86.12614571 85.34538641\n",
      " 85.37610922 86.48122307 85.06970433 85.19086587 83.59542307 82.21475444\n",
      " 82.9774589  82.35410911 82.2292628  82.84002281 83.31082379 84.69770866\n",
      " 82.86553984 81.94846151 79.58212834 79.53881791 78.77544076 78.86134721\n",
      " 78.63862394 78.52325658 79.7583393  78.9468078  78.82140714 78.56872461\n",
      " 78.25960971 79.51236362 80.1094347  79.88608147 78.85718255 77.9153684\n",
      " 77.88779979 77.24681912 79.74815438 79.66508862 78.30548263 77.85717855\n",
      " 75.05294005 73.37331461 73.93129815 75.74967764 75.75329282 77.5688372\n",
      " 78.2356091  78.91104492 78.5489067  78.64768602 80.09773096 80.873178\n",
      " 82.12332364 81.03342854 81.37570754 81.341428   81.18848213 81.42575786\n",
      " 81.62784711 83.22780682 84.45219703 83.69094517 84.59273053 82.5337062\n",
      " 81.83814383 81.92676199 82.57945575 82.80637074 81.86739213 81.12836637\n",
      " 81.91905093 82.60570093 81.0534729  79.98091335 76.99219204 77.45300408\n",
      " 78.04330605 77.41278847 76.108051   75.69156153 78.25510309 76.86079585\n",
      " 73.89876726 72.2233031  73.63472788 74.721555   76.15612541 76.45222599\n",
      " 79.6950218  78.89525837 77.70388447 78.37589664 76.34641388 75.58594635\n",
      " 74.18363215 71.89460306 73.17129049 74.51094729 77.05544504 76.05669767\n",
      " 74.44694497 75.95572628 74.22360022 70.90484676 69.90176108 70.0064629\n",
      " 68.26830266 68.7080367  66.77825745 67.43389295 69.36487789 69.12548781\n",
      " 70.26890272 70.86519628 70.52463209 71.93892872 71.86298613 70.42448672\n",
      " 71.93082641 70.27320068 67.97970049 68.32282021 68.57470611 69.00445669\n",
      " 71.35923468 72.8457914  74.76150447 75.78462167 73.48397209 72.19404218\n",
      " 75.23353192 75.47357271 72.23205535 70.34679649 70.62527678 70.65714311\n",
      " 69.80576737 70.50322731 71.8369971  70.67090803 70.85124286 71.41648725\n",
      " 67.79895664 67.44142647 68.72400033 69.57173908 70.47785532 71.45526678\n",
      " 72.16619611 71.00124059 71.9897348  70.69323694 68.44153478 68.56933921\n",
      " 68.20136894 68.70610169 67.63627503 68.81922114 69.05471097 69.27037035\n",
      " 69.88392474 70.679545   69.68592945 68.84264329 68.70336229 68.5967998\n",
      " 68.61739754 69.75163029 69.01727128 68.50932837 67.63903684 68.41141019\n",
      " 68.64251685 70.07963648 70.09965056 70.99940534 70.67964017 70.3265751\n",
      " 70.87403977 70.38249736 68.80560584 69.07860702 70.20380065 70.31203579\n",
      " 70.53499054 71.08852261 71.79481781 73.13133511 73.89326562 74.13944039\n",
      " 74.35879243 73.92540179 73.97878326 76.26312066 78.75261812 78.26722814\n",
      " 80.03246899 79.10537845 78.62294205 76.59594758 75.61601131 75.35882564\n",
      " 74.69225232 73.39359378 73.88096891 73.24164517 72.91935181 72.72942082\n",
      " 73.58961652 71.45201119 71.70053348 70.93212427 71.15157649 72.28238297\n",
      " 73.68295718 71.86992536 70.91883566 70.99373324 71.55341591 72.47286535\n",
      " 72.65916694 71.14011227 70.74431203 69.70848565 68.63928738 70.13414074\n",
      " 69.86139777 68.59476018 67.78702777 66.6988922  66.62975989 67.6799394\n",
      " 66.71375834 66.57025414 67.49368769 67.08738323 67.13906651 68.06288261\n",
      " 67.52236295 67.05208976 68.17140521 68.36847804 68.82959069 69.07900595\n",
      " 69.7597141  69.71141657 69.36097193 70.71177023 71.36006703 71.83278896\n",
      " 67.20663627 64.36370493 60.61583274 59.63315568 59.83334047 60.40257567\n",
      " 61.4276975  61.41228753 61.68737501 62.01468345 63.79017954 63.39124777\n",
      " 63.47914607 63.47517166 63.45591486 63.43673018 63.44397974 63.44333268\n",
      " 63.44304198 63.44304198 64.53829631 64.28003998 64.28170475 64.28170475\n",
      " 64.28747562 64.28747562 64.28747562 64.29558653 64.32195263 64.31287002\n",
      " 64.31287002 64.29380426 64.27191888 64.23739969 64.29380426 62.17773679\n",
      " 62.54278388 62.54278388 62.52817994 62.54593979 62.56290535 62.54013404\n",
      " 62.53290274 62.53290274 62.53290274 62.53290274 62.53290274 62.88596161\n",
      " 62.82273818 62.82273818 62.81913668 62.81913668 62.82841939 62.82841939\n",
      " 62.83241443 62.83241443 62.83787571 62.83787571 62.83787571 62.83787571\n",
      " 62.83837075 62.83837075 62.83837075 62.83837075 62.83837075 62.84729591\n",
      " 62.84729591 62.84729591 62.84729591 62.51997157 62.45764563 62.45764563\n",
      " 62.45764563 62.45764563 62.45764563 62.45764563 62.45764563 62.45672705\n",
      " 62.45672705 62.45672705 62.45672705 62.45672705 62.45672705 62.45672705\n",
      " 62.45672705 62.45672705 62.45672705 62.45672705 62.45672705 62.45672705\n",
      " 62.45672705 62.45672705 62.45672705 62.45450284 62.45450284 62.45450284\n",
      " 62.45450284 62.45450284 62.45450284 62.45159501 62.45159501 62.45159501\n",
      " 62.45159501 62.45159501 62.45159501 62.45159501 62.45159501 62.45159501\n",
      " 62.45159501 62.45159501 62.45159501 62.45159501 62.45159501 62.45159501\n",
      " 62.45159501 62.45159501 62.45159501 62.45159501 62.45159501 62.45159501\n",
      " 62.45159501 62.45159501 62.45159501 62.45159501 62.45159501 62.45159501\n",
      " 62.45159501]\n",
      "\n",
      "Predicting using model: XGBoost_best-1\n",
      "Predicted values: [82.73147  82.83469  82.29062  81.19886  79.73546  80.84416  81.119545\n",
      " 81.48549  80.77073  78.264824 78.718346 79.634705 80.40352  80.736206\n",
      " 81.993645 83.071106 85.500336 86.72525  87.29659  86.10029  87.17938\n",
      " 88.1067   89.071175 88.35558  89.92588  89.79663  91.45842  92.31491\n",
      " 89.70549  89.6487   89.698814 89.52809  89.36361  93.170006 92.480774\n",
      " 91.70897  89.26516  89.613396 85.33874  82.692986 82.645546 86.68767\n",
      " 85.5119   84.19732  83.13424  86.73328  87.0188   86.23442  89.3077\n",
      " 89.43795  89.218216 85.77826  84.27715  84.73413  82.99384  85.94403\n",
      " 82.00688  81.82374  81.61983  82.90404  81.19336  82.06929  77.68166\n",
      " 75.61998  76.28006  77.195786 77.91139  78.416695 77.38212  72.65444\n",
      " 74.56699  77.49501  77.23614  75.20997  75.36032  74.828094 76.618904\n",
      " 77.45784  76.927315 74.66933  73.275276 72.78486  70.11167  69.83709\n",
      " 71.597664 71.3442   69.00637  69.77978  72.09076  71.43888  72.50453\n",
      " 73.136925 75.045296 73.45962  74.37708  75.32588  74.33297  71.83848\n",
      " 72.004166 71.230576 72.55672  72.11003  74.304405 71.04115  72.02874\n",
      " 71.977165 72.79659  73.90332  72.39975  71.65808  74.07646  74.12782\n",
      " 74.7983   74.30751  75.60725  77.62718  77.203445 77.73211  77.3477\n",
      " 75.905624 74.537094 72.32863  72.70781  73.94129  74.62476  75.94588\n",
      " 76.95944  76.24113  78.24877  77.780785 78.058975 79.00878  78.35152\n",
      " 76.93147  78.811874 76.93042  77.25911  78.88139  78.38041  78.4323\n",
      " 80.31432  79.31442  78.348465 79.62414  78.40065  78.29176  77.5216\n",
      " 78.05793  79.56671  81.22825  80.88654  82.792534 82.76574  81.568886\n",
      " 81.09185  81.098915 82.41124  81.952515 81.58446  83.18972  84.29699\n",
      " 85.17116  85.376976 86.11454  86.350845 85.693665 85.42939  85.739716\n",
      " 85.103096 85.910774 85.074715 84.971245 83.13961  82.93276  83.92903\n",
      " 82.71189  82.64334  82.886955 83.05818  84.30109  82.59526  81.99254\n",
      " 79.54981  78.84154  78.204384 78.86757  78.478546 78.489136 79.375946\n",
      " 78.48281  78.9292   78.2904   78.31451  79.09113  80.022675 79.756165\n",
      " 78.44066  77.69311  77.44451  77.32854  79.96614  79.7732   78.24298\n",
      " 77.43288  74.60672  73.30153  74.16919  75.7941   75.809845 77.49038\n",
      " 77.97581  79.179115 78.90044  78.57975  80.39754  81.2322   82.25167\n",
      " 80.893906 81.628426 81.324936 81.40687  81.5584   81.77895  83.187195\n",
      " 83.95399  83.32294  83.92311  82.32428  81.99846  82.10701  82.70772\n",
      " 82.54813  81.9424   81.07795  82.29216  82.33482  80.60634  80.00605\n",
      " 76.75591  77.60566  78.15717  77.029045 76.10948  75.50002  78.156044\n",
      " 77.07333  73.69095  72.31706  73.45382  74.9228   76.39369  76.79957\n",
      " 79.3097   78.64955  77.740265 78.36098  76.38869  74.89809  74.481445\n",
      " 72.09316  73.02915  74.46801  77.26932  76.03702  74.677666 76.01724\n",
      " 74.051575 70.90105  69.41498  69.84498  68.27289  69.18394  66.43496\n",
      " 67.46065  69.734955 69.15675  70.32769  71.25361  70.56185  71.949135\n",
      " 72.02925  70.352806 71.80912  70.149155 68.31375  68.58577  68.66355\n",
      " 69.572395 71.04128  72.873375 74.83588  75.93852  73.52169  72.27793\n",
      " 75.52163  75.519806 72.0212   69.765594 70.385414 70.638336 69.349525\n",
      " 70.6069   72.13094  70.67967  70.79345  71.75745  67.30913  67.78843\n",
      " 69.012215 69.48061  70.56182  72.007126 72.13354  70.87038  71.84905\n",
      " 70.64112  68.38836  68.94447  68.39608  68.895325 67.60597  68.89872\n",
      " 69.10611  69.21558  70.01679  70.89638  68.90637  68.95601  68.698364\n",
      " 68.33193  68.82579  69.81662  69.09595  68.45549  67.49428  68.35497\n",
      " 68.80103  70.032104 70.10906  71.0275   70.68143  70.24634  70.84565\n",
      " 70.02683  69.11493  69.350105 70.51751  70.10128  70.53665  71.148415\n",
      " 71.94352  73.021385 74.04012  74.11013  74.44298  73.835526 73.8537\n",
      " 76.55404  78.864456 78.07984  80.14489  78.70888  78.21876  76.49622\n",
      " 75.83442  75.08853  74.79157  73.12223  74.04016  73.23794  73.01038\n",
      " 72.87663  73.40295  71.74914  71.4579   71.148415 71.25617  72.360306\n",
      " 74.06409  72.13772  70.966286 71.099655 71.725876 72.43569  72.565926\n",
      " 70.9888   70.84275  69.29344  68.58581  70.72841  69.89919  68.74012\n",
      " 67.93105  66.250046 66.34673  67.66535  66.615974 66.35353  67.547066\n",
      " 66.83615  67.61605  67.99319  67.75097  67.153435 68.23596  68.41974\n",
      " 69.040405 69.02816  69.94604  70.22491  69.212074 71.138405 71.51444\n",
      " 71.691124 66.98853  62.89939  61.093304 59.761166 60.395958 60.48252\n",
      " 61.67267  61.494953 61.459423 62.31221  64.162186 63.014324 63.402916\n",
      " 63.39281  63.37479  63.37225  63.355125 63.40659  63.378674 63.378674\n",
      " 64.58712  64.19249  64.19738  64.25734  64.26188  64.35333  64.38058\n",
      " 64.37696  64.37696  64.363335 64.36765  64.363846 64.3617   64.368256\n",
      " 64.3704   62.72492  63.153793 63.16162  63.156822 63.15114  63.15114\n",
      " 63.106857 63.072964 63.072964 63.072964 63.072964 63.072964 62.78528\n",
      " 62.529976 62.529976 62.529976 62.571053 62.571053 62.571053 62.600113\n",
      " 62.600113 62.600113 62.600113 62.600113 62.600113 62.600113 62.600113\n",
      " 62.600113 62.600113 62.600113 62.600113 62.600113 62.600113 62.600113\n",
      " 62.794186 62.735775 62.735775 62.735775 62.735775 62.735775 62.735775\n",
      " 62.735775 62.735775 62.735775 62.735775 62.735775 62.735775 62.735775\n",
      " 62.735775 62.735775 62.735775 62.735775 62.735775 62.735775 62.735775\n",
      " 62.735775 62.735775 62.735775 62.735775 62.735775 62.735775 62.735775\n",
      " 62.735775 62.735775 62.735775 62.735775 62.735775 62.735775 62.735775\n",
      " 62.735775 62.735775 62.735775 62.735775 62.735775 62.735775 62.735775\n",
      " 62.735775 62.735775 62.735775 62.735775 62.735775 62.735775 62.735775\n",
      " 62.735775 62.735775 62.735775 62.735775 62.735775 62.735775 62.735775\n",
      " 62.735775 62.735775]\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define the model directory\n",
    "model_dir = hybrid_models_dir.get(commodity.upper())\n",
    "\n",
    "# Define the model directory\n",
    "meta_dir = hybrid_meta_models_dir.get(commodity.upper())\n",
    "hybridmodel_name = 'meta_model_'+commodity+'.pkl'\n",
    "hybrid_meta_model_name = os.path.join(meta_dir, hybridmodel_name)\n",
    "# Load the meta-model (used in stacked hybrid)\n",
    "with open(hybrid_meta_model_name, 'rb') as f:\n",
    "    meta_model = pickle.load(f)\n",
    "\n",
    "# Function to load models\n",
    "def load_saved_models(directory):\n",
    "    model_files = [f for f in os.listdir(directory) if f.endswith('.pkl')]\n",
    "    models = {}\n",
    "    for file in model_files:\n",
    "        model_path = os.path.join(directory, file)\n",
    "        model_name = file.replace(\".pkl\", \"\")\n",
    "        model = joblib.load(model_path)\n",
    "        models[model_name] = model\n",
    "    return models\n",
    "\n",
    "# Load all saved models\n",
    "loaded_models = load_saved_models(model_dir)\n",
    "\n",
    "\n",
    "def predict_from_model(model_name, model):\n",
    "    if \"XGBOOST\" in model_name.upper():\n",
    "        model = model.fit(X_train_scaled_minmax, y_train_scaled)\n",
    "        xgb_predictions = model.predict(X_test_scaled_minmax)\n",
    "        xgb_prediction = scaler_minmax.inverse_transform(xgb_predictions.reshape(-1, 1)).ravel()\n",
    "        y_test_org = scaler_minmax.inverse_transform(y_train_scaled.reshape(-1, 1)).ravel()\n",
    "        return scaler_minmax.inverse_transform(xgb_predictions.reshape(-1, 1)).ravel()\n",
    "\n",
    "    elif \"RF\" in model_name.upper():\n",
    "        #  Remove Sentiment & Macroeconomic Features from Training Data\n",
    "        exclude_columns = ['GDP', 'Interest_rates','Inflation_rate', 'DebtToGDP', 'ETF_Value', 'Sentiment_score', 'Sentiment_Rolling_14',\n",
    "        'Sentiment_Rolling_30', 'Sentiment_smoothed']\n",
    "        X_train_filtered = pd.DataFrame(X_train_scaled_minmax, columns=X_train.columns).drop(columns=exclude_columns, errors='ignore').fillna(0.0)\n",
    "        X_test_filtered = pd.DataFrame(X_test_scaled_minmax, columns=X_test.columns).drop(columns=exclude_columns, errors='ignore').fillna(0.0)\n",
    "\n",
    "        random_search = model.fit(X_train_filtered, y_train_scaled)\n",
    "        y_pred_rf = random_search.predict(X_test_filtered)\n",
    "        return  scaler_minmax.inverse_transform(y_pred_rf.reshape(-1, 1)).ravel()\n",
    "\n",
    "    elif \"LSTM\" in model_name.upper():\n",
    "        #  Select Sentiment + Microeconomic Features\n",
    "        selected_features = [\n",
    "            'Open', 'High', 'Low', 'Volume', 'lag_1', 'lag_7', 'lag_30',\n",
    "            'MA_7', 'MA_30', 'MA_90', 'Log_Returns', 'volatility_7', 'volatility_30',\n",
    "            'Sentiment_score', 'Sentiment_Rolling_14', 'Sentiment_Rolling_30'\n",
    "        ]\n",
    "        \n",
    "        # Extract Features for Training & Testing\n",
    "        X_train_selected = pd.DataFrame(X_train_scaled_standard, columns=X_train.columns)[selected_features].values\n",
    "        X_test_selected = pd.DataFrame(X_test_scaled_standard, columns=X_test.columns)[selected_features].values\n",
    "        \n",
    "        #  Reshape Data for LSTM (3D: Samples, Time Steps, Features)\n",
    "        look_back = 14  # Using the same look-back period\n",
    "        \n",
    "        def create_sequences(X, y, look_back):\n",
    "            Xs, ys = [], []\n",
    "            for i in range(len(X) - look_back):\n",
    "                Xs.append(X[i:i + look_back])\n",
    "                ys.append(y[i + look_back])\n",
    "            return np.array(Xs), np.array(ys)\n",
    "        \n",
    "        X_train_seq, y_train_seq = create_sequences(X_train_selected, y_train_scaled, look_back)\n",
    "        X_test_seq, y_test_seq = create_sequences(X_test_selected, y_test_scaled, look_back)\n",
    "        #  Train Model\n",
    "        model = model.fit(\n",
    "            X_train_seq, y_train_seq,\n",
    "            epochs=50, batch_size=32, \n",
    "            validation_data=(X_test_seq, y_test_seq),\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        #  Predict on Test Set\n",
    "        y_pred_lstm_scaled = model.predict(X_test_seq)\n",
    "        \n",
    "        #  Inverse Transform Predictions to Original Scale\n",
    "        y_pred_lstm_original = scaler_minmax.inverse_transform(y_pred_lstm_scaled)\n",
    "        return y_pred_lstm_original\n",
    "\n",
    "    elif \"ARIMA\" in model_name.upper(): \n",
    "        # Select microeconomic factors from the scaled data\n",
    "        exog_train = X_train_scaled_minmax[:, [X_train.columns.get_loc(col) for col in ['Interest_rates', 'Inflation_rate', 'GDP', 'DebtToGDP', 'ETF_Value','Sentiment_score']]]\n",
    "        exog_test = X_test_scaled_minmax[:, [X_test.columns.get_loc(col) for col in ['Interest_rates', 'Inflation_rate', 'GDP', 'DebtToGDP', 'ETF_Value','Sentiment_score']]]\n",
    "        model2 = model.get_forecast(steps=len(y_test), exog=exog_test)\n",
    "        fc_model2 = model2.predicted_mean\n",
    "        return fc_model2.values\n",
    "        \n",
    "    elif \"GARCH\" in model_name.upper():\n",
    "        y_train_log_returns = np.log(y_train / y_train.shift(1)).dropna()\n",
    "        y_test_log_returns = np.log(y_test / y_test.shift(1)).dropna()\n",
    "        garch_forecast = model.forecast(horizon=len(y_test_log_returns))\n",
    "        garch_forecast_series = garch_forecast.mean.iloc[-len(y_test_log_returns):].values.flatten()\n",
    "        # Convert forecasted log returns back to price predictions\n",
    "        y_test_prices = y_test.iloc[-len(garch_forecast_series):].values\n",
    "        garch_predicted_prices = y_test_prices[0] * np.exp(np.cumsum(garch_forecast_series))\n",
    "        return garch_predicted_prices\n",
    "        \n",
    "    elif \"VAR\" in model_name.upper():\n",
    "        # Ensure data is stationary (apply differencing)\n",
    "        train_var = train_df[['Close', 'Volume', 'MA_7', 'MA_30', 'MA_90', 'Log_Returns', \n",
    "                              'volatility_7', 'volatility_30', 'Sentiment_Rolling_14', 'Sentiment_Rolling_30']].diff().dropna()\n",
    "        test_var = test_df[['Close', 'Volume', 'MA_7', 'MA_30', 'MA_90', 'Log_Returns', \n",
    "                            'volatility_7', 'volatility_30', 'Sentiment_Rolling_14', 'Sentiment_Rolling_30']].diff().dropna()\n",
    "        \n",
    "        # train_var = train_df[['Close', 'Volume', 'MA_7', 'MA_30']].diff().dropna()\n",
    "        # test_var = test_df[['Close', 'Volume', 'MA_7', 'MA_30']].diff().dropna()\n",
    "        train_exog = train_df[['GDP', 'Interest_rates', 'Inflation_rate', 'DebtToGDP', 'ETF_Value']].iloc[1:]\n",
    "        test_exog = test_df[['GDP', 'Interest_rates', 'Inflation_rate', 'DebtToGDP', 'ETF_Value',]].iloc[1:]\n",
    "        \n",
    "        # train_exog = train_df[['GDP', 'Interest_rates', 'Inflation_rate', 'ETF_Value']].iloc[1:]  # Align with differencing\n",
    "        # test_exog = test_df[['GDP', 'Interest_rates', 'Inflation_rate', 'ETF_Value']].iloc[1:]    # Align with differencing\n",
    "        \n",
    "        # Select optimal lag using BIC\n",
    "        var_model = VAR(endog=train_var, exog=train_exog)\n",
    "        lag_selection = var_model.select_order(maxlags=15)\n",
    "        optimal_lag = lag_selection.bic\n",
    "        print(f\"Optimal lag order (BIC): {optimal_lag}\")\n",
    "        \n",
    "        # Fit VAR model\n",
    "        var_fitted = var_model.fit(optimal_lag)\n",
    "        \n",
    "        # Forecast\n",
    "        forecast_steps = len(test_var)\n",
    "        last_observations = train_var.values[-optimal_lag:]\n",
    "        \n",
    "        # Forecast with exogenous variables\n",
    "        var_forecast = var_fitted.forecast(last_observations, steps=forecast_steps, exog_future=test_exog)\n",
    "        \n",
    "        # Convert forecasted differenced values back to original scale\n",
    "        forecast_df_m4 = pd.DataFrame(var_forecast, columns=train_var.columns, index=test_var.index)\n",
    "        forecast_df_m4 = train_df[['Close', 'Volume', 'MA_7', 'MA_30', 'MA_90', 'Log_Returns', 'volatility_7', 'volatility_30', 'Sentiment_Rolling_14', 'Sentiment_Rolling_30']].iloc[-1] + forecast_df_m4.cumsum()\n",
    "        \n",
    "        # Extract predicted Close prices\n",
    "        predicted_prices = forecast_df_m4['Close']\n",
    "        return predicted_prices\n",
    "    else:\n",
    "        print(f\"Unknown model type for {model_name}. Skipping.\")\n",
    "        return None\n",
    "\n",
    "predict_d= {}\n",
    "for model_name, model in loaded_models.items():\n",
    "    print(f\"\\nPredicting using model: {model_name}\")\n",
    "    prediction = predict_from_model(model_name, model)\n",
    "    predict_d[model_name]=prediction\n",
    "    if prediction is not None:\n",
    "        print(\"Predicted values:\", prediction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e5e3e0-754b-4722-bd8f-17316db85599",
   "metadata": {},
   "source": [
    "### 8.2 Load Pretrained Hybrid Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "faf91b77-5ea3-4f99-bc43-207e0934817c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stacking\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "best1_forecast_trimmed,best2_forecast_trimmed = list(predict_d.values())\n",
    "# Create a new dataset with ARIMA and XGBoost predictions\n",
    "X_combined = np.column_stack([best2_forecast_trimmed,best1_forecast_trimmed])\n",
    "# Normalize input features (optional but recommended)\n",
    "X_combined_scaled = scaler_minmax.fit_transform(X_combined)\n",
    "\n",
    "# Final predictions from the hybrid model\n",
    "hybrid_predictions_stacked = meta_model.predict(X_combined_scaled)\n",
    "\n",
    "# Create a new dataset with ARIMA and XGBoost predictions\n",
    "X_combined = np.column_stack(list(predict_d.values()))\n",
    "# Normalize input features (optional but recommended)\n",
    "X_combined_scaled = scaler_minmax.fit_transform(X_combined)\n",
    "\n",
    "# Final predictions from the hybrid model\n",
    "hybrid_predictions_stacked = meta_model.predict(X_combined_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73c8145-ff5c-4e40-8b88-cec070a45a42",
   "metadata": {},
   "source": [
    "### 8.3 Predict Price with Stacked Hybrid Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "950818b5-f757-4e30-9efc-6f8e1f340441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted future values from the hybrid model:\n",
      "            Hybrid Forecast\n",
      "2025-04-26        68.591005\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "n = 1 # Number of future predictions\n",
    "\n",
    "# Step 1: Ensure Predictions Are in NumPy Format\n",
    "future_best1_values = np.array(best1_forecast_trimmed[-n:]).reshape(-1, 1)\n",
    "future_best2_values = np.array(best2_forecast_trimmed[-n:]).reshape(-1, 1)\n",
    "\n",
    "# Step 2: Prepare Feature Matrix for Future Predictions\n",
    "X_combined_future = np.column_stack([future_best1_values, future_best2_values])\n",
    "\n",
    "# Step 3: Fit MinMaxScaler on Training Data (if not already fitted)\n",
    "scaler_minmax.fit(X_combined)  # Ensure the scaler is trained on past data\n",
    "X_combined_future_scaled = scaler_minmax.transform(X_combined_future)\n",
    "\n",
    "# Step 4: Predict Future Prices Using Hybrid Model\n",
    "hybrid_predictions_future = meta_model.predict(X_combined_future_scaled)\n",
    "\n",
    "# Step 5: Convert to 1D array\n",
    "hybrid_predictions_future = hybrid_predictions_future.flatten()\n",
    "\n",
    "# Step 6: Store Predictions in DataFrame\n",
    "future_dates = pd.date_range(start=y_test.index[-1], periods=n + 1, freq='D')[1:]\n",
    "future_price = pd.DataFrame({\n",
    "    'Hybrid Forecast': hybrid_predictions_future\n",
    "}, index=future_dates)\n",
    "\n",
    "# Step 7: Display Predicted Future Prices\n",
    "print(\"Predicted future values from the hybrid model:\")\n",
    "print(future_price)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ffc83d-cfd7-447f-87cc-129d63a79d7c",
   "metadata": {},
   "source": [
    "### 8.4 Let's verify Price with Weighted Hybrid Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9ba22c1f-8369-4e45-8f28-e8f4ca110018",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from math import sqrt\n",
    "min_length = min(len(best1_forecast_trimmed),len(best2_forecast_trimmed))\n",
    "y_test_trimmed = y_test[:min_length].values.flatten()\n",
    "\n",
    "# Calculate RMSE for both models\n",
    "rmse_best1 = sqrt(mean_squared_error(y_test_trimmed, best1_forecast_trimmed))\n",
    "rmse_best2 = sqrt(mean_squared_error(y_test_trimmed, best2_forecast_trimmed))\n",
    "\n",
    "# Compute weights using inverse RMSE\n",
    "weight_best1 = (1 / rmse_best1) / ((1 / rmse_best1) + (1 / rmse_best2))\n",
    "weight_best2 = (1 / rmse_best2) / ((1 / rmse_best1) + (1 / rmse_best2))\n",
    "\n",
    "# Weighted hybrid model predictions\n",
    "hybrid_weighted_predictions = (weight_best1 * best1_forecast_trimmed) + (weight_best2 * best2_forecast_trimmed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68402ad-ebf6-4330-bb48-a6906893604c",
   "metadata": {},
   "source": [
    "### 8.5 Predict Price with Weighted Hybrid Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0c256007-7f61-4263-b511-5c0bcd6a1576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Hybrid_Weighted\n",
      "2025-04-26        62.604509\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "\n",
    "# Step 1: Ensure Predictions Are in NumPy Format\n",
    "future_best1_values = np.array(best1_forecast_trimmed[-n:]).reshape(-1, 1)\n",
    "future_best2_values = np.array(best2_forecast_trimmed[-n:]).reshape(-1, 1)\n",
    "\n",
    "# Step 2: Compute Hybrid Model Predictions\n",
    "\n",
    "## 1. Simple Averaging Hybrid Model\n",
    "hybrid_avg_future = (future_best1_values.flatten() + future_best2_values.flatten()) / 2\n",
    "\n",
    "## 2. Weighted Hybrid Model (Based on RMSE Inverse Weights)\n",
    "weight_best1 = (1 / rmse_best1) / ((1 / rmse_best1) + (1 / rmse_best2))\n",
    "weight_best2 = (1 / rmse_best2) / ((1 / rmse_best1) + (1 / rmse_best2))\n",
    "hybrid_weighted_future = (weight_best1 * future_best1_values.flatten()) + (weight_best2 * future_best2_values.flatten())\n",
    "\n",
    "# Step 3: Store Predictions in DataFrame\n",
    "future_dates = pd.date_range(start=y_test.index[-1], periods=n + 1, freq='D')[1:]\n",
    "future_price = pd.DataFrame({\n",
    "    'Hybrid_Weighted': hybrid_weighted_future,\n",
    "}, index=future_dates)\n",
    "print(future_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2837b8-f173-4e52-9aa3-0acde10b9b8c",
   "metadata": {},
   "source": [
    "### 8.6 Future Price Prediction and recommendation to Buy or Sell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "df537ec3-1dc0-461b-89bd-e118ff307688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Evaluation Metrics (on last known actual prices) with historical data from 2003:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>R2 Score</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Weighted Hybrid</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.659301</td>\n",
       "      <td>0.415491</td>\n",
       "      <td>0.415491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stacked Hybrid</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.840059</td>\n",
       "      <td>5.571005</td>\n",
       "      <td>5.571005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Average Hybrid</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.676476</td>\n",
       "      <td>0.426315</td>\n",
       "      <td>0.426315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Model  R2 Score      MAPE      RMSE       MAE\n",
       "0  Weighted Hybrid       0.0  0.659301  0.415491  0.415491\n",
       "1   Stacked Hybrid       0.0  8.840059  5.571005  5.571005\n",
       "2   Average Hybrid       0.0  0.676476  0.426315  0.426315"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n Evaluation Metrics (on last known actual prices) with historical data from 2003:\")\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "88c49695-41d5-4bb6-9e5a-7627dd43b0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last Actual Observed Price: 63.02\n",
      "\n",
      "Predicted future values and investment recommendation:\n",
      "            Future Price Weighted  Future Price Stacked  Future Price Average  \\\n",
      "2025-04-26              62.604509             68.591005             62.593685   \n",
      "2025-04-27              62.604509             68.591005             62.593685   \n",
      "2025-04-28              62.604509             68.591005             62.593685   \n",
      "2025-04-29              62.604509             68.591005             62.593685   \n",
      "2025-04-30              62.604509             68.591005             62.593685   \n",
      "\n",
      "           Recommendation  \n",
      "2025-04-26        HOLD ⚖️  \n",
      "2025-04-27        HOLD ⚖️  \n",
      "2025-04-28        HOLD ⚖️  \n",
      "2025-04-29        HOLD ⚖️  \n",
      "2025-04-30        HOLD ⚖️  \n",
      "\n",
      "Evaluation Metrics (on last known actual prices):\n",
      "             Model    MAPE    RMSE     MAE  Accuracy (%)\n",
      "0   Average Hybrid  0.6765  0.4263  0.4263       99.3235\n",
      "1  Weighted Hybrid  0.6593  0.4155  0.4155       99.3407\n",
      "2   Stacked Hybrid  8.8401  5.5710  5.5710       91.1599\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "n = 5  # Number of future predictions\n",
    "threshold = 5  # Decision threshold in USD\n",
    "\n",
    "# Step 1: Ensure Predictions Are in NumPy Format\n",
    "future_best1_values = np.array(best1_forecast_trimmed[-n:]).reshape(-1, 1)\n",
    "future_best2_values = np.array(best2_forecast_trimmed[-n:]).reshape(-1, 1)\n",
    "\n",
    "# Step 2: Prepare Feature Matrix for Future Predictions\n",
    "X_combined_future = np.column_stack([future_best1_values, future_best2_values])\n",
    "\n",
    "# Step 3: Scale and Predict\n",
    "scaler_minmax.fit(X_combined)  # Use previously prepared training combined features\n",
    "X_combined_future_scaled = scaler_minmax.transform(X_combined_future)\n",
    "\n",
    "# Hybrid predictions\n",
    "hybrid_predictions_weighted = (weight_best1 * future_best1_values.flatten()) + (weight_best2 * future_best2_values.flatten())\n",
    "hybrid_predictions_stacked = meta_model.predict(X_combined_future_scaled).flatten()\n",
    "hybrid_predictions_average = (future_best1_values.flatten() + future_best2_values.flatten()) / 2\n",
    "\n",
    "# Step 4: Store Future Predictions\n",
    "future_dates = pd.date_range(start=y_test.index[-1], periods=n + 1, freq='D')[1:]\n",
    "future_price = pd.DataFrame({\n",
    "    'Future Price Weighted': hybrid_predictions_weighted,\n",
    "    'Future Price Stacked': hybrid_predictions_stacked,\n",
    "    'Future Price Average': hybrid_predictions_average\n",
    "}, index=future_dates)\n",
    "\n",
    "# Step 5: Last Observed Price\n",
    "last_actual_price = y_test.values[-1]\n",
    "\n",
    "# Step 6: Recommendation Based on Weighted Hybrid\n",
    "recommendation = []\n",
    "for forecast in hybrid_predictions_weighted:\n",
    "    price_diff = forecast - last_actual_price\n",
    "    if price_diff > threshold:\n",
    "        recommendation.append(\"BUY 📈\")\n",
    "    elif price_diff < -threshold:\n",
    "        recommendation.append(\"SELL 📉\")\n",
    "    else:\n",
    "        recommendation.append(\"HOLD ⚖️\")\n",
    "\n",
    "future_price['Recommendation'] = recommendation\n",
    "\n",
    "# Display Predictions\n",
    "print(f\"Last Actual Observed Price: {last_actual_price:.2f}\\n\")\n",
    "print(\"Predicted future values and investment recommendation:\")\n",
    "print(future_price)\n",
    "\n",
    "# ======================================\n",
    "# Evaluation Metrics on Known y_test[-n:]\n",
    "# ======================================\n",
    "actual_values = y_test[-n:].values.flatten()\n",
    "\n",
    "def mape(y_true, y_pred): \n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    return 100 - mape(y_true, y_pred)\n",
    "\n",
    "# Store results\n",
    "metrics_summary = {\n",
    "    \"Model\": [\"Average Hybrid\", \"Weighted Hybrid\", \"Stacked Hybrid\"],\n",
    "    \n",
    "    \"MAPE\": [\n",
    "        mape(actual_values, hybrid_predictions_average),\n",
    "        mape(actual_values, hybrid_predictions_weighted),\n",
    "        mape(actual_values, hybrid_predictions_stacked)\n",
    "    ],\n",
    "    \"RMSE\": [\n",
    "        np.sqrt(mean_squared_error(actual_values, hybrid_predictions_average)),\n",
    "        np.sqrt(mean_squared_error(actual_values, hybrid_predictions_weighted)),\n",
    "        np.sqrt(mean_squared_error(actual_values, hybrid_predictions_stacked))\n",
    "    ],\n",
    "    \"MAE\": [\n",
    "        mean_absolute_error(actual_values, hybrid_predictions_average),\n",
    "        mean_absolute_error(actual_values, hybrid_predictions_weighted),\n",
    "        mean_absolute_error(actual_values, hybrid_predictions_stacked)\n",
    "    ],\n",
    "    \"Accuracy (%)\": [\n",
    "        accuracy(actual_values, hybrid_predictions_average),\n",
    "        accuracy(actual_values, hybrid_predictions_weighted),\n",
    "        accuracy(actual_values, hybrid_predictions_stacked)\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Convert to DataFrame and show\n",
    "metrics_df = pd.DataFrame(metrics_summary)\n",
    "print(\"\\nEvaluation Metrics (on last known actual prices):\")\n",
    "print(metrics_df.round(4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2098a754-5d68-4670-84f4-8d0685d6a865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Accuracy (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Average Hybrid</td>\n",
       "      <td>0.6765</td>\n",
       "      <td>0.4263</td>\n",
       "      <td>0.4263</td>\n",
       "      <td>99.3235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Weighted Hybrid</td>\n",
       "      <td>0.6593</td>\n",
       "      <td>0.4155</td>\n",
       "      <td>0.4155</td>\n",
       "      <td>99.3407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stacked Hybrid</td>\n",
       "      <td>8.8401</td>\n",
       "      <td>5.5710</td>\n",
       "      <td>5.5710</td>\n",
       "      <td>91.1599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Model    MAPE    RMSE     MAE  Accuracy (%)\n",
       "0   Average Hybrid  0.6765  0.4263  0.4263       99.3235\n",
       "1  Weighted Hybrid  0.6593  0.4155  0.4155       99.3407\n",
       "2   Stacked Hybrid  8.8401  5.5710  5.5710       91.1599"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63213624-5aa3-45d0-93db-aecdf70691ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e7aef6-ee7c-40b1-b330-2f658c8600fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468d8a36-4255-4533-bd32-ccec992dcede",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2845e7e2-6ea8-4286-be21-1d5270c73298",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e625b6d6-06f4-44b3-91de-dbb17454326c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fdf96f-cc4e-484a-a0c7-e690c756e73b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a74e8b-64ee-4111-a72c-682c512ea2c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bcaea2-7a41-4c72-b636-7b415273088f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5da76fb-abf5-47df-978b-f228359ee343",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5832f94e-dc11-40b7-b1fd-cf06e9d8649a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255fdd46-3344-4078-bd60-15a1fb266464",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd540f6-3ecb-4114-9cc7-5a32f416ab42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb263913-bf96-4118-9fb8-d615cb0535b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32019d8-d4db-46cf-b530-c825698689b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cee20da-8875-4434-8f32-f40c2a89c63d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7d8275-451f-4b40-8e0a-a6f7a9c26801",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce16445-fcba-4727-a874-57a43a267fc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
